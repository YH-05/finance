{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e07c32",
   "metadata": {},
   "source": [
    "# FRED API Test\n",
    "\n",
    "-   2025/8/20 é–‹ç™ºé€”ä¸­\n",
    "-   [GEMINI](https://gemini.google.com/app/1348d8b8b8741164?utm_source=app_launcher&utm_medium=owned&utm_campaign=base_all)\n",
    "-   CSV å½¢å¼ã§ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã¨ SQLite å½¢å¼ã§ã®ãƒ‡ãƒ¼ã‚¿ä¿å­˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72882e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DFF': {'name': 'FFé‡‘åˆ© (å®ŸåŠ¹é‡‘åˆ©)',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'æœ€ã‚‚åŸºæœ¬çš„ãªç±³å›½ã®æ”¿ç­–é‡‘åˆ©ã€‚é‡‘èæ©Ÿé–¢ãŒç›¸äº’ã«è³‡é‡‘ã‚’è²¸ã—å€Ÿã‚Šã™ã‚‹éš›ã®é‡‘åˆ©ï¼ˆç„¡æ‹…ä¿ç¿Œæ—¥ç‰©ï¼‰ã®å®Ÿç¸¾å€¤ã€‚'},\n",
       " 'FEDFUNDS': {'name': 'FFé‡‘åˆ© (æœˆæ¬¡å¹³å‡)',\n",
       "  'frequency': 'æœˆæ¬¡',\n",
       "  'description': 'DFFã®æœˆæ¬¡å¹³å‡å€¤ã€‚æœˆæ¬¡ã®åˆ†æã«åˆ©ç”¨ã€‚'},\n",
       " 'SOFR': {'name': 'SOFR',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'æ‹…ä¿ä»˜ç¿Œæ—¥ç‰©èª¿é”é‡‘åˆ©ã€‚ç±³å›½å‚µã‚’æ‹…ä¿ã¨ã™ã‚‹ç¿Œæ—¥ç‰©ã®ãƒ¬ãƒå–å¼•é‡‘åˆ©ã€‚'},\n",
       " 'DPRIME': {'name': 'ãƒ—ãƒ©ã‚¤ãƒ ãƒ¬ãƒ¼ãƒˆ',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'éŠ€è¡ŒãŒæœ€å„ªè‰¯ä¼æ¥­ã¸çŸ­æœŸèè³‡ã‚’è¡Œã†éš›ã®æœ€å„ªé‡è²¸å‡ºé‡‘åˆ©ã€‚'},\n",
       " 'DGS3MO': {'name': 'ç±³å›½å‚µ3ãƒ¶æœˆç‰©',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'çŸ­æœŸé‡‘åˆ©ã®ä»£è¡¨æ ¼ã€‚é‡‘èæ”¿ç­–ã®å¤‰æ›´ã«æ•æ„Ÿã«åå¿œã€‚'},\n",
       " 'DGS2': {'name': 'ç±³å›½å‚µ2å¹´ç‰©',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'çŸ­æœŸé‡‘åˆ©ã€‚è¿‘ã„å°†æ¥ã®é‡‘èæ”¿ç­–ã«å¯¾ã™ã‚‹å¸‚å ´ã®æœŸå¾…ã‚’åæ˜ ã€‚'},\n",
       " 'DGS10': {'name': 'ç±³å›½å‚µ10å¹´ç‰©åˆ©å›ã‚Š',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'é•·æœŸé‡‘åˆ©ã®æœ€ã‚‚é‡è¦ãªæŒ‡æ¨™ã€‚æ ªä¾¡ã®è©•ä¾¡ï¼ˆãƒ‡ã‚£ã‚¹ã‚«ã‚¦ãƒ³ãƒˆãƒ¬ãƒ¼ãƒˆï¼‰ã«å½±éŸ¿ã€‚'},\n",
       " 'DGS30': {'name': 'ç±³å›½å‚µ30å¹´ç‰©',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'è¶…é•·æœŸã®é‡‘åˆ©ã€‚å¹´é‡‘åŸºé‡‘ãªã©ã®é•·æœŸæŠ•è³‡å®¶ã®å‹•å‘ã‚’åæ˜ ã€‚'},\n",
       " 'T10Y2Y': {'name': 'é•·çŸ­é‡‘åˆ©å·® (10å¹´-2å¹´)',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'æ™¯æ°—å¾Œé€€ã®å¼·åŠ›ãªå…ˆè¡ŒæŒ‡æ¨™ã€‚ãƒã‚¤ãƒŠã‚¹ï¼ˆé€†ã‚¤ãƒ¼ãƒ«ãƒ‰ï¼‰ã¯æ™¯æ°—å¾Œé€€ã‚’ç¤ºå”†ã€‚'},\n",
       " 'T10Y3M': {'name': 'é•·çŸ­é‡‘åˆ©å·® (10å¹´-3ãƒ¶æœˆ)',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'T10Y2Yã¨åŒæ§˜ã«æ™¯æ°—å¾Œé€€ã®å…ˆè¡ŒæŒ‡æ¨™ã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã‚‹ã€‚'},\n",
       " 'T10YIE': {'name': 'æœŸå¾…ã‚¤ãƒ³ãƒ•ãƒ¬ç‡(10å¹´)',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'å¸‚å ´ãŒäºˆæƒ³ã™ã‚‹å°†æ¥10å¹´é–“ã®å¹³å‡ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ã€‚'},\n",
       " 'DAAA': {'name': 'ãƒ ãƒ¼ãƒ‡ã‚£ãƒ¼ã‚º Aaaç¤¾å‚µ',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'ä¿¡ç”¨æ ¼ä»˜ã‘ãŒæœ€ã‚‚é«˜ã„ï¼ˆAaaï¼‰äº‹æ¥­ä¼šç¤¾ã®ç¤¾å‚µåˆ©å›ã‚Šã€‚'},\n",
       " 'DBAA': {'name': 'ãƒ ãƒ¼ãƒ‡ã‚£ãƒ¼ã‚º Baaç¤¾å‚µ',\n",
       "  'frequency': 'æ—¥æ¬¡',\n",
       "  'description': 'ä¿¡ç”¨æ ¼ä»˜ã‘ãŒä¸­ç¨‹åº¦ï¼ˆBaaï¼‰ã®äº‹æ¥­ä¼šç¤¾ã®ç¤¾å‚µåˆ©å›ã‚Šã€‚'},\n",
       " 'MORTGAGE30US': {'name': '30å¹´å›ºå®šä½å®…ãƒ­ãƒ¼ãƒ³é‡‘åˆ©',\n",
       "  'frequency': 'é€±æ¬¡',\n",
       "  'description': 'ç±³å›½ã®ä½å®…å¸‚å ´ã®å‹•å‘ã‚’æ¸¬ã‚‹ä¸Šã§é‡è¦ãªæŒ‡æ¨™ã€‚'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import json\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from fredapi import Fred\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def find_ancestor_dir(dir_name: str) -> Path | None:\n",
    "    \"\"\"\n",
    "    ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åå‰ã‚’æŒ‡å®šã—ã¦æ¢ã—å‡ºã™é–¢æ•°\n",
    "    \"\"\"\n",
    "    current_dir = Path().cwd()\n",
    "    for parent in current_dir.parents:\n",
    "        if parent.name == dir_name:\n",
    "            return parent\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_fred_series_incrementally(\n",
    "    series_id: str, frequency: str, fred_instance: Fred\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®é®®åº¦ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å¤ã„å ´åˆã¯å·®åˆ†ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’APIã‹ã‚‰å–å¾—ã—ã¦æ›´æ–°ã™ã‚‹ã€‚\n",
    "\n",
    "    Args:\n",
    "        series_id (str): FREDã®ã‚·ãƒªãƒ¼ã‚ºID\n",
    "        frequency (str): ãƒ‡ãƒ¼ã‚¿æ›´æ–°é »åº¦\n",
    "        fred_instance (Fred): Fred APIã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿\n",
    "    \"\"\"\n",
    "    cache_file_path = os.path.join(CACHE_DIR, f\"{series_id}.csv\")\n",
    "    freshness_threshold_days = {\"æ—¥æ¬¡\": 1, \"é€±æ¬¡\": 7, \"æœˆæ¬¡\": 30, \"å››åŠæœŸ\": 90}.get(\n",
    "        frequency, 1\n",
    "    )\n",
    "\n",
    "    # 1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "    if not os.path.exists(cache_file_path):\n",
    "        print(\n",
    "            f\"ğŸ“‰ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’APIã‹ã‚‰å–å¾—ã—ã¾ã™: '{series_id}'\"\n",
    "        )\n",
    "        try:\n",
    "            full_data = fred_instance.get_series(series_id)\n",
    "            full_data.to_csv(cache_file_path)\n",
    "            return full_data\n",
    "        except Exception as e:\n",
    "            print(f\"ã‚¨ãƒ©ãƒ¼: {series_id} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
    "            return None\n",
    "\n",
    "    # 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€é®®åº¦ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "    file_mod_time = os.path.getmtime(cache_file_path)\n",
    "    age_days = (time.time() - file_mod_time) / (60 * 60 * 24)\n",
    "\n",
    "    # 2a. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæ–°é®®ãªå ´åˆ\n",
    "    if age_days <= freshness_threshold_days:\n",
    "        print(f\"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯æ–°é®®ã§ã™ã€‚'{series_id}' ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ã€‚\")\n",
    "        return pd.read_csv(cache_file_path, index_col=0, parse_dates=True).iloc[:, 0]\n",
    "\n",
    "    # 2b. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤ã„å ´åˆ -> å·®åˆ†æ›´æ–°ã‚’å®Ÿè¡Œ\n",
    "    print(f\"ğŸ”„ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤ã„ãŸã‚ã€'{series_id}' ã®å·®åˆ†æ›´æ–°ã‚’è©¦ã¿ã¾ã™ã€‚\")\n",
    "    try:\n",
    "        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€æœ€å¾Œã®æ—¥ä»˜ã‚’å–å¾—\n",
    "        existing_data = pd.read_csv(\n",
    "            cache_file_path, index_col=0, parse_dates=True\n",
    "        ).iloc[:, 0]\n",
    "        last_date = existing_data.index.max()\n",
    "\n",
    "        # å–å¾—é–‹å§‹æ—¥ã‚’æœ€å¾Œã®æ—¥ä»˜ã®ç¿Œæ—¥ã«è¨­å®š\n",
    "        start_date_for_new_data = last_date + timedelta(days=1)\n",
    "\n",
    "        # APIã‹ã‚‰æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’å–å¾—\n",
    "        print(\n",
    "            f\"   -> {start_date_for_new_data.strftime('%Y-%m-%d')}ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’APIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¾ã™ã€‚\"\n",
    "        )\n",
    "        new_data = fred_instance.get_series(\n",
    "            series_id, observation_start=start_date_for_new_data\n",
    "        )\n",
    "\n",
    "        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
    "        if not new_data.empty:\n",
    "            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨æ–°ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ\n",
    "            combined_data = pd.concat([existing_data, new_data])\n",
    "            # é‡è¤‡ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰ã‚’å‰Šé™¤\n",
    "            combined_data = combined_data[~combined_data.index.duplicated(keep=\"last\")]\n",
    "\n",
    "            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°\n",
    "            combined_data.to_csv(cache_file_path)\n",
    "            print(f\"   -> {len(new_data)}ä»¶ã®æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚\")\n",
    "            return combined_data\n",
    "        else:\n",
    "            # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ™‚åˆ»ã ã‘ã‚’æ›´æ–°ã—ã¦ã€Œãƒã‚§ãƒƒã‚¯æ¸ˆã¿ã€ã¨ã™ã‚‹\n",
    "            print(\"   -> æ–°è¦ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "            os.utime(cache_file_path, None)  # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç¾åœ¨æ™‚åˆ»ã«æ›´æ–°\n",
    "            return existing_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ã‚¨ãƒ©ãƒ¼: {series_id} ã®å·®åˆ†æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}\")\n",
    "        # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™\n",
    "        return pd.read_csv(cache_file_path, index_col=0, parse_dates=True).iloc[:, 0]\n",
    "\n",
    "\n",
    "ROOT_DIR = find_ancestor_dir(\"papers-1\")\n",
    "Q_DIR = Path().cwd().parent.parent\n",
    "DATA_DIR = Q_DIR / \"data\" / \"MSCI_KOKUSAI\"\n",
    "PRJ_DIR = Q_DIR / \"A_001\"\n",
    "ROOT_DIR = find_ancestor_dir(\"papers-1\")\n",
    "FRED_DIR = ROOT_DIR / \"FRED\"\n",
    "CACHE_DIR = FRED_DIR / \"cache\"\n",
    "\n",
    "\n",
    "# FRED\n",
    "load_dotenv()\n",
    "api_fred = os.getenv(\"FRED_API_KEY\")\n",
    "\n",
    "with open(FRED_DIR / \"fred_series.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    series_info = json.load(f)\n",
    "\n",
    "display(series_info[\"Interest Rates\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04c5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
