# 設計レビューレポート - ca_strategy パッケージ
# 生成日時: 2026-02-18
# レビュー方式: Agent Teams (4並列 pr-design エージェント + 手動統合)
# 対象PR: #3590 feat(ca-strategy): AI駆動の競争優位性ベース投資戦略パッケージ（PoC）を実装

metadata:
  generated_at: "2026-02-18"
  pr_number: 3590
  review_type: "design"
  review_method: "agent-teams-4-parallel"
  modules_reviewed: 16

# ===========================================================================
# 総合スコア
# ===========================================================================
scores:
  pipeline_architecture: 72   # orchestrator, extractor, scorer
  data_models: 75              # types, transcript, transcript_parser, pit
  infrastructure: 90           # batch, cost, _config, _llm_utils
  portfolio_construction: 78   # aggregator, neutralizer, portfolio_builder, output
  overall: 78                  # 加重平均 (pipeline×0.30 + models×0.25 + infra×0.20 + portfolio×0.25)

# ===========================================================================
# グループ1: パイプラインアーキテクチャ (72/100)
# ===========================================================================
group_1_pipeline:
  modules:
    - orchestrator.py   # 685 lines
    - extractor.py      # 658 lines
    - scorer.py         # 656 lines

  solid_compliance:
    single_responsibility: "WARN"   # orchestrator がフェーズ実行 + チェックポイントI/O + 状態管理の3責務
    open_closed: "WARN"             # run_from_checkpoint() の if-chain が拡張困難
    liskov_substitution: "PASS"
    interface_segregation: "PASS"
    dependency_inversion: "PASS"    # DIP-001修正済み (Anthropicクライアント注入)

  issues:
    - id: "TYPE-001"
      severity: "HIGH"
      category: "type_safety"
      location: "orchestrator.py:305-307"
      description: "_execute_phase() の func パラメータが Any 型。戻り値も Any。"
      recommendation: >
        Protocol または Callable[[...], T] を使用して型安全にする。
        各フェーズの戻り値型が異なるため、overload デコレータまたは
        Phase ごとの個別実行メソッドへの分割を検討。
      effort: "medium"

    - id: "DRY-002"
      severity: "MEDIUM"
      category: "dry"
      location: "orchestrator.py:581-631"
      description: >
        _save_checkpoint_claims() と _save_checkpoint_scored() が
        ほぼ同一のロジック（差異はファイル名とモデル型のみ）。
        _load_checkpoint_claims() と _load_checkpoint_scored() も同様。
      recommendation: >
        ジェネリックな _save_checkpoint(data, filename, model_cls) と
        _load_checkpoint(filename, model_cls) を作成し4メソッドを統合。
      effort: "low"

    - id: "OCP-001"
      severity: "MEDIUM"
      category: "solid"
      location: "orchestrator.py:run_from_checkpoint()"
      description: >
        フェーズ1〜5の実行順序が if-elif チェーンでハードコード。
        新しいフェーズ追加時にメソッド全体の修正が必要。
      recommendation: >
        PoC段階では許容範囲。本格化時は Phase Protocol + Registry パターン
        で各フェーズをプラグイン化することを検討。
      effort: "high"

    - id: "DRY-004"
      severity: "LOW"
      category: "dry"
      location: "extractor.py / scorer.py"
      description: >
        ClaimExtractor と ClaimScorer の __init__ パターンが類似
        （KB ディレクトリ読み込み、system prompt 構築、BatchProcessor 初期化）。
        共通の基底クラスまたは Template Method で統合可能。
      recommendation: >
        PoC段階では現状維持で問題なし。Phase 1/2 の処理が分岐する場合は
        Template Method パターンの導入を検討。
      effort: "medium"

  strengths:
    - "DIP-001: Anthropic クライアントのコンストラクタ注入が実装済み"
    - "DRY-001: call_llm() の共通ヘルパー抽出済み（_llm_utils.py）"
    - "SEC-001: プロンプトインジェクション防御がシステムプロンプトに組み込み済み"
    - "BatchProcessor による並列処理とリトライが適切に統合されている"
    - "CostTracker がフェーズ単位でLLMコストを記録しており、$50 閾値で警告"

# ===========================================================================
# グループ2: データモデル・型安全性 (75/100)
# ===========================================================================
group_2_data_models:
  modules:
    - types.py              # 473 lines
    - transcript.py         # 283 lines
    - transcript_parser.py  # 598 lines
    - pit.py                # 136 lines

  solid_compliance:
    single_responsibility: "PASS"   # 各モジュールが単一責務
    open_closed: "PASS"
    liskov_substitution: "PASS"
    interface_segregation: "PASS"
    dependency_inversion: "PASS"

  issues:
    - id: "DRY-003"
      severity: "HIGH"
      category: "dry"
      location: "types.py (複数箇所)"
      description: >
        8つ以上のフィールドで同一の「0.0 <= v <= 1.0」範囲バリデータが重複。
        対象: confidence, final_confidence, aggregate_score, structural_weight,
        weight (PortfolioHolding), score (PortfolioHolding), benchmark_weight,
        actual_weight, weight (BenchmarkWeight)。
        各フィールドに個別の @field_validator メソッドが定義されている。
      recommendation: >
        Annotated 型エイリアスで統一:
        UnitFloat = Annotated[float, AfterValidator(_validate_unit_range)]
        同様に _validate_non_negative_int() も共通化可能。
      effort: "low"
      affected_fields:
        - "RuleEvaluation.confidence"
        - "ScoredClaim.final_confidence"
        - "StockScore.aggregate_score"
        - "StockScore.structural_weight"
        - "PortfolioHolding.weight"
        - "PortfolioHolding.score"
        - "SectorAllocation.benchmark_weight"
        - "SectorAllocation.actual_weight"
        - "BenchmarkWeight.weight"

    - id: "ABS-001"
      severity: "MEDIUM"
      category: "abstraction"
      location: "transcript_parser.py:155-241"
      description: >
        parse_all_months() が3フェーズ（レコード収集 → 重複排除 → 解析・書き込み）を
        単一メソッドで実行。サイクロマティック複雑度は約12。
      recommendation: >
        各フェーズをプライベートメソッドに抽出:
        _collect_all_records(), _deduplicate_records() (既存),
        _process_all_records()。メインメソッドは3行の委譲のみに。
      effort: "low"

    - id: "NAMING-001"
      severity: "LOW"
      category: "naming"
      location: "transcript_parser.py:195"
      description: "_sedol 変数は実際にはトップレベルキー（SEDOL以外も含む）。"
      recommendation: "_ （アンダースコアのみ）に変更し、未使用であることを明示。"
      effort: "trivial"

    - id: "CONSISTENCY-001"
      severity: "LOW"
      category: "consistency"
      location: "transcript_parser.py vs types.py"
      description: >
        transcript_parser.py は @dataclass(frozen=True) の ParseResult を使用。
        他の全モデルは Pydantic BaseModel(frozen=True)。
        ParseResult は内部データ転送のみのため実害は軽微だが、一貫性に欠ける。
      recommendation: >
        PoC段階では現状維持で問題なし。ParseResult は統計情報のみで
        バリデーション不要のため dataclass が適切とも言える。
      effort: "low"

  strengths:
    - "全 Pydantic モデルで frozen=True が一貫して適用されている"
    - "NonEmptyStr 型エイリアスにより空文字列バリデーションが統一済み（DRY-002修正）"
    - "ClaimType = Literal[...] で列挙値が型安全"
    - "PoiT (Point-in-Time) モジュールが独立しており、バックテスト整合性を保証"
    - "TranscriptLoader が Pydantic バリデーションと PoiT フィルタリングを統合"
    - "_SAFE_TICKER_PATTERN でパストラバーサル攻撃を防御"

# ===========================================================================
# グループ3: インフラモジュール (90/100)
# ===========================================================================
group_3_infrastructure:
  modules:
    - batch.py      # 368 lines
    - cost.py       # 290 lines
    - _config.py    # 75 lines
    - _llm_utils.py # 196 lines

  solid_compliance:
    single_responsibility: "PASS"   # 各モジュールが明確な単一責務
    open_closed: "PASS"             # BatchProcessor[T, R] ジェネリックで拡張可能
    liskov_substitution: "PASS"
    interface_segregation: "PASS"
    dependency_inversion: "PASS"

  issues:
    - id: "THREAD-001"
      severity: "LOW"
      category: "concurrency"
      location: "cost.py:128"
      description: >
        record() 内で self._lock を保持したまま get_total_cost() を呼び出している。
        get_total_cost() は Lock を取得しないため、同一スレッドからは問題ないが、
        record() のロック範囲が必要以上に広い可能性がある。
      recommendation: >
        現在の実装は正しく動作する（Lock は non-reentrant だが同一スレッド内での
        get_total_cost() 呼び出しはロック不要）。PoC段階では現状維持。
      effort: "trivial"

  strengths:
    - "BatchProcessor[T, R] が PEP 695 ジェネリック構文を使用し型安全"
    - "CheckpointManager による中間チェックポイント保存（PERF-002実装済み）"
    - "指数バックオフリトライで ValueError/TypeError をスキップする設計が適切"
    - "CostTracker がスレッドセーフ（threading.Lock）でJSON永続化対応"
    - "ConfigRepository が cached_property で設定の遅延読み込みを実現"
    - "_llm_utils.py への共通LLM操作の抽出（DRY-001）が適切に実装済み"
    - "モジュールサイズが適切（75〜368行）で高い凝集度を維持"

# ===========================================================================
# グループ4: ポートフォリオ構築 (78/100)
# ===========================================================================
group_4_portfolio:
  modules:
    - aggregator.py         # 243 lines
    - neutralizer.py        # 141 lines
    - portfolio_builder.py  # 383 lines
    - output.py             # 427 lines

  solid_compliance:
    single_responsibility: "PASS"
    open_closed: "WARN"     # output.py の出力フォーマットが拡張困難
    liskov_substitution: "PASS"
    interface_segregation: "PASS"
    dependency_inversion: "PASS"

  issues:
    - id: "TYPE-002"
      severity: "HIGH"
      category: "type_safety"
      location: "output.py:122, output.py:215"
      description: >
        _write_json() と _write_summary() の as_of_date パラメータが
        object 型で定義されている。PortfolioResult.as_of_date は date 型。
      recommendation: "object → date に変更。from datetime import date をインポート。"
      effort: "trivial"

    - id: "TYPE-003"
      severity: "MEDIUM"
      category: "type_safety"
      location: "portfolio_builder.py:71"
      description: >
        build() メソッドの ranked パラメータが list[dict] 型。
        dict の内部構造（ticker, aggregate_score, gics_sector 等）が
        型レベルで保証されない。
      recommendation: >
        TypedDict を定義して型安全にする:
        class RankedStock(TypedDict):
            ticker: str
            aggregate_score: float
            gics_sector: str
            sector_rank: int
            claim_count: int
            structural_weight: float
      effort: "low"

    - id: "OCP-002"
      severity: "LOW"
      category: "solid"
      location: "output.py"
      description: >
        4つの出力フォーマット（JSON, CSV, Markdown, Rationale）が
        個別メソッドとしてハードコードされている。新フォーマット追加時に
        クラス本体の修正が必要。
      recommendation: >
        PoC段階では許容範囲。本格化時は OutputWriter Protocol と
        Registry パターンで各フォーマットをプラグイン化。
      effort: "medium"

    - id: "UTIL-001"
      severity: "LOW"
      category: "simplification"
      location: "output.py:408"
      description: "_mean() ヘルパーが独自実装されているが、statistics.mean() で代替可能。"
      recommendation: "from statistics import mean を使用。空リスト対応は呼び出し元で guard。"
      effort: "trivial"

  strengths:
    - "ScoreAggregator の構造的優位性重み付け（rule_6: 1.5x, rule_11: 2.0x）が適切"
    - "CAGR接続品質によるブースト/ペナルティ（±10%）が投資ロジックと整合"
    - "SectorNeutralizer が factor.core.normalizer.Normalizer を適切にラップ"
    - "Hamilton法（最大剰余法）による比例配分が数学的に正確"
    - "PortfolioBuilder の frozen=True 対応でオブジェクト再生成パターンを採用"
    - "frozenset による不変ルール集合の定義が適切"

# ===========================================================================
# クロスモジュール分析
# ===========================================================================
cross_module_analysis:
  data_flow:
    description: >
      Phase 1 (extractor) → Phase 2 (scorer) → Phase 3 (aggregator + neutralizer) →
      Phase 4 (portfolio_builder) → Phase 5 (output) のデータフローは一方向で明確。
      Orchestrator が各フェーズ間のデータ受け渡しを制御。
    assessment: "GOOD"

  coupling:
    description: >
      モジュール間の結合度は低い。各フェーズは Pydantic モデルのみを介して連携。
      extractor/scorer は types.py の Claim/ScoredClaim に依存。
      portfolio_builder は types.py の PortfolioHolding/PortfolioResult に依存。
      唯一の懸念は orchestrator.py が全モジュールに依存する点だが、
      これは Orchestrator の本質的な役割であり問題ない。
    assessment: "GOOD"

  cohesion:
    description: >
      各モジュールの凝集度は高い。特にインフラモジュール（batch, cost, _config, _llm_utils）は
      単一の明確な責務を持つ。types.py は全データモデルを集約しており、
      473行と大きいが、論理的なグルーピング（Transcript / Claim / Score / Portfolio / Config）
      がコメントで明示されている。
    assessment: "GOOD"

  immutability:
    description: >
      全 Pydantic モデルが frozen=True で一貫。transcript_parser.py の
      ParseResult も @dataclass(frozen=True)。パイプライン全体で
      不変オブジェクトベースのデータフローが実現されている。
    assessment: "EXCELLENT"

# ===========================================================================
# 推奨アクション（優先度順）
# ===========================================================================
recommended_actions:
  required:
    - priority: 1
      id: "DRY-003"
      action: "types.py の 0.0-1.0 範囲バリデータを UnitFloat 型エイリアスに統合"
      effort: "low"
      impact: "9つのバリデータメソッドを1つの共通型に削減"

    - priority: 2
      id: "TYPE-002"
      action: "output.py の as_of_date: object → date に修正"
      effort: "trivial"
      impact: "型安全性の向上"

  suggested:
    - priority: 3
      id: "TYPE-003"
      action: "portfolio_builder.py の ranked: list[dict] → TypedDict に変更"
      effort: "low"
      impact: "API境界の型安全性向上"

    - priority: 4
      id: "DRY-002"
      action: "orchestrator.py のチェックポイント save/load メソッドを汎用化"
      effort: "low"
      impact: "4メソッド → 2メソッドに削減"

    - priority: 5
      id: "ABS-001"
      action: "transcript_parser.py の parse_all_months() を3メソッドに分割"
      effort: "low"
      impact: "複雑度を12 → 各4程度に削減"

    - priority: 6
      id: "TYPE-001"
      action: "orchestrator.py の _execute_phase() の func: Any を型安全に"
      effort: "medium"
      impact: "パイプライン実行の型安全性向上"

  deferred:
    - id: "OCP-001"
      action: "フェーズ実行の Phase Protocol + Registry パターン化"
      note: "PoC段階では過剰設計。本格化時に検討。"

    - id: "OCP-002"
      action: "output.py の OutputWriter Protocol + Registry パターン化"
      note: "PoC段階では4フォーマットで十分。"

    - id: "DRY-004"
      action: "extractor/scorer の Template Method 統合"
      note: "PoC段階では別クラスとして明確で問題なし。"

# ===========================================================================
# サマリー
# ===========================================================================
summary:
  verdict: "APPROVE"
  overall_score: 78
  comment: >
    ca_strategy パッケージは PoC としては良好な設計品質を持つ。
    特にインフラモジュール（90/100）は高い完成度。
    主要な改善点は types.py のバリデータ重複（DRY-003）と
    output.py の型安全性（TYPE-002）で、いずれも低コストで修正可能。
    パイプラインアーキテクチャの拡張性（OCP-001/002）は
    PoC段階では許容範囲であり、本格化フェーズで対応すべき。
    全体として frozen=True による不変オブジェクト設計、
    Pydantic バリデーション、BatchProcessor によるリトライ/並列化など、
    堅実な設計判断がなされている。
