# VI-a. モート戦略 — 差別化の持続性

> 06_open-questions.md 論点1「差別化の持続性（モート）」の議論結果

## 前提：AIファンドに「強いモート」は存在しうるか

伝統的なモートのフレームワークをAIファンドに適用すると、構造的に弱いことが明らかになる。

| 伝統的なモート     | AIファンドでの適用                       | 評価                       |
| ------------------ | ---------------------------------------- | -------------------------- |
| 規模の経済         | 運用資産が大きくなるほどコスト効率↑      | △ 一定規模超えると逆に不利 |
| ネットワーク効果   | 投資家が増えてもファンドの質は上がらない | × ほぼ不成立               |
| スイッチングコスト | 投資家は簡単に資金を引き上げられる       | × 弱い                     |
| 規制による障壁     | ファンド免許、コンプライアンス体制       | △ テーブルステークス       |
| ブランド           | 実績+透明性で構築                        | ○ 時間がかかる             |
| 知的財産           | LLMベースでは特許が取りにくい            | × 弱い                     |

**モートにならないもの**:

- LLMの性能自体（全員がGPT-5/Claude 5を使える）
- MASアーキテクチャのパターン（技術ブログで公開される）
- データソース（SEC EDGAR, yfinance等は全員がアクセス可能）
- 単純な自動化（すぐに追随される）

## モート候補の全体像

検討したモート候補と評価：

| モート                            | 概要                                                  | 構築難度 | 強度     | 時間軸 |
| --------------------------------- | ----------------------------------------------------- | -------- | -------- | ------ |
| A. 知識モート                     | MASが発見する市場パターンや非効率性自体が知的資産     | 中       | 中〜高   | 1年〜  |
| B. プラットフォーム化             | 投資家が自分の哲学でMASを動かせる基盤を提供           | 高       | 高       | 2年〜  |
| C. 人間FM + AI CIOモデル          | 人+システムの統合体としてのモート                     | 中       | 中       | 即座   |
| D. オープンソース戦略             | Red Hatモデル。フレームワークのデファクト化           | 中       | 高       | 1年〜  |
| E. データ生成ループ               | Teslaモデル。MASの運用自体がデータ生成装置            | 高       | 高       | 1年〜  |
| F. 規制先行                       | 規制当局と協力して業界標準を先に作る                  | 非常に高 | 非常に高 | 3年〜  |
| G. バーティカル特化               | 特定ニッチに特化したMASを提供                         | 低       | 中       | 即座   |
| H. エージェントマーケットプレイス | Numerai進化版。エージェント投稿によるネットワーク効果 | 高       | 非常に高 | 2年〜  |

### 棄却した方向性

- **3層の時間稼ぎモート**（哲学統合→データ蓄積→トラックレコード）: 「時間を稼ぐ」だけであり、構造的な参入障壁としては不十分
- **C. 人間FM + AI CIOモデル**: スケールしない問題がある

## 採用方針：Knowledge Discovery Platform（KDP）

**A（知識モート）+ B（プラットフォーム）+ E（データ生成ループ）の統合戦略**を採用する。

### コア仮説

> MASは「ファンド」ではなく「投資知識の発見・検証・蓄積を行うプラットフォーム」である。ファンドはそのプラットフォームの最初のアプリケーションにすぎない。

ファンドとして考えるとモートは弱いが、**プラットフォームとして考えると複数のモートが重層的に成立する**。

### アーキテクチャの3層構造

```
┌─────────────────────────────────────────────────┐
│  Layer 3: Applications（アプリケーション層）        │
│  ・自社ファンド運用                                │
│  ・投資家向けダッシュボード                         │
│  ・リサーチレポート配信                             │
│  ・アラート/シグナル提供                            │
└─────────────────────────────────────────────────┘
                        ▲
┌─────────────────────────────────────────────────┐
│  Layer 2: Knowledge Engine（知識エンジン層）        │
│  ・投資仮説の生成 → 検証 → 確信度スコアリング       │
│  ・市場パターンのカタログ化                         │
│  ・因果関係グラフの構築                             │
│  ・エージェント判断の事後分析                       │
└─────────────────────────────────────────────────┘
                        ▲
┌─────────────────────────────────────────────────┐
│  Layer 1: MAS Core（マルチエージェント基盤層）      │
│  ・エージェントオーケストレーション                  │
│  ・データ収集・正規化パイプライン                    │
│  ・投資哲学（dogma）エンジン                       │
│  ・判断ログ・データ生成ループ                       │
└─────────────────────────────────────────────────┘
```

### Layer 2（Knowledge Engine）— モートの核心

Layer 2 は以下のサイクルを自動的に回す：

#### ステップ1: 仮説生成

MASの各エージェントが投資判断を行う過程で、暗黙的に仮説を生成する。

例：

- 「AMATの競争優位性は半導体装置の寡占構造に依存している」
- 「金利上昇局面ではクオリティファクターがアウトパフォームする」

#### ステップ2: 仮説の構造化

生成された仮説を検証可能な形式に変換する。

```json
{
    "claim": "金利上昇局面でクオリティファクターがアウトパフォーム",
    "conditions": ["10Y Treasury yield > 前月比 +25bp", "期間: 3ヶ月"],
    "measurable_outcome": "Quality Factor ETF vs S&P 500 超過リターン > 0",
    "confidence": 0.65,
    "evidence_sources": ["FRED data", "factor analysis", "historical backtest"]
}
```

#### ステップ3: 自動検証

条件が成立した時点で仮説の結果を自動追跡し、信頼度を更新。

#### ステップ4: 知識のカタログ化

検証結果が蓄積され、投資知識のグラフが構築される。

```
                 金利上昇
                /        \
    クオリティ↑          グロース↓
       |                    |
   高ROE銘柄↑         高PER銘柄↓
       |                    |
   AMAT, MSFT ↑        TSLA, RIVN ↓
```

### モートとしての機能

| 要素                       | モートとしての機能                                                        |
| -------------------------- | ------------------------------------------------------------------------- |
| 仮説の量と質               | 運用期間 × エージェント数に比例。後発者は同じ時間をかけないと追いつけない |
| 検証済み仮説のカタログ     | バックテストではなく**リアルタイムの市場で検証された**仮説群。独自資産    |
| 因果関係グラフ             | 個々の仮説ではなく、仮説間の関係性。模倣がきわめて困難                    |
| エージェント判断のメタ分析 | 「どのエージェントがどの市場環境で信頼できるか」のメタ知識                |

### 段階的展開

| Phase   | 内容                                                                       | 時間軸    |
| ------- | -------------------------------------------------------------------------- | --------- |
| Phase 1 | 自社ファンド専用で運用し、Knowledge Engineを育てる                         | 0-12ヶ月  |
| Phase 2 | リサーチレポート・シグナルの形で知識を販売                                 | 12-24ヶ月 |
| Phase 3 | 投資家が自分のdogma.mdでKnowledge Engineを利用できるプラットフォームを開放 | 24-36ヶ月 |
| Phase 4 | サードパーティエージェントの受け入れ → エコシステム形成                    | 36ヶ月〜  |

Phase 3以降でネットワーク効果が成立する：

- 投資家Aの仮説検証結果が、投資家Bの判断精度を向上させる（匿名化して）
- エージェントの多様性が増すほど、仮説の発見能力が向上する

### 既存MASとの接続点

| KDP層                     | 既存の対応コンポーネント                        | ギャップ                     |
| ------------------------- | ----------------------------------------------- | ---------------------------- |
| Layer 1: MAS Core         | dr-stock, dr-industry, ca-eval のエージェント群 | 概ね構築済み                 |
| Layer 2: Knowledge Engine | —                                               | **未構築（新規設計が必要）** |
| Layer 3: Applications     | 週次レポート、金融記事                          | 部分的に構築済み             |

## 残る論点

1. **Layer 2 の最小実装は何か？** — 仮説の生成・構造化・追跡をどの程度自動化できるか
2. **データの量は十分か？** — 有意な知識を蓄積するために必要な運用期間・銘柄数は
3. **フリーライダー問題** — Phase 3以降で、知識だけ利用して貢献しない投資家への対処
4. **知識の陳腐化** — 市場構造が変化した場合、過去の仮説はどう更新されるか
5. **論点2（投資戦略の洗練メカニズム）との接続** — Knowledge Engineは論点2のTUMIX型/リーダーボード型とどう統合するか
