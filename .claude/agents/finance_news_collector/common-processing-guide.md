# é‡‘èãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå…±é€šå‡¦ç†ã‚¬ã‚¤ãƒ‰

ã“ã®ã‚¬ã‚¤ãƒ‰ã¯ã€ãƒ†ãƒ¼ãƒåˆ¥ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆfinance-news-{theme}ï¼‰ã®å…±é€šå‡¦ç†ã‚’å®šç¾©ã—ã¾ã™ã€‚

## å…±é€šè¨­å®š

- **Issueãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**: `.github/ISSUE_TEMPLATE/news-article.md`ï¼ˆMarkdownå½¢å¼ï¼‰
- **GitHub Project**: #15 (`PVT_kwHOBoK6AM4BMpw_`)
- **Statusãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰**: `PVTSSF_lAHOBoK6AM4BMpw_zg739ZE`
- **å…¬é–‹æ—¥æ™‚ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰**: `PVTF_lAHOBoK6AM4BMpw_zg8BzrI`ï¼ˆDateå‹ã€ã‚½ãƒ¼ãƒˆç”¨ï¼‰

## ä½¿ç”¨ãƒ„ãƒ¼ãƒ«

å„ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ä»¥ä¸‹ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š

```yaml
tools:
  - Read              # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
  - Bash              # gh CLIå®Ÿè¡Œ
  - MCPSearch         # MCPãƒ„ãƒ¼ãƒ«æ¤œç´¢ãƒ»ãƒ­ãƒ¼ãƒ‰
  - mcp__rss__fetch_feed   # RSSãƒ•ã‚£ãƒ¼ãƒ‰æ›´æ–°
  - mcp__rss__get_items    # RSSè¨˜äº‹å–å¾—
```

## Phase 1: åˆæœŸåŒ–

### ã‚¹ãƒ†ãƒƒãƒ—1.1: MCPãƒ„ãƒ¼ãƒ«ã®ãƒ­ãƒ¼ãƒ‰

```python
def load_mcp_tools() -> bool:
    """MCPãƒ„ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""

    try:
        # MCPSearchã§RSSãƒ„ãƒ¼ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        MCPSearch(query="select:mcp__rss__fetch_feed")
        MCPSearch(query="select:mcp__rss__get_items")
        return True
    except Exception as e:
        ãƒ­ã‚°å‡ºåŠ›: f"è­¦å‘Š: MCPãƒ„ãƒ¼ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}"
        ãƒ­ã‚°å‡ºåŠ›: "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™"
        return False
```

### ã‚¹ãƒ†ãƒƒãƒ—1.2: æ—¢å­˜Issueå–å¾—ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰

```bash
gh issue list \
    --repo YH-05/finance \
    --label "news" \
    --state all \
    --limit 100 \
    --json number,title,body,createdAt
```

### ã‚¹ãƒ†ãƒƒãƒ—1.3: çµ±è¨ˆã‚«ã‚¦ãƒ³ã‚¿åˆæœŸåŒ–

```python
processed = 0       # å–å¾—ã—ãŸè¨˜äº‹ç·æ•°
date_filtered = 0   # å…¬é–‹æ—¥æ™‚ãƒ•ã‚£ãƒ«ã‚¿ã§ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸä»¶æ•°
matched = 0         # ãƒ†ãƒ¼ãƒã«ãƒãƒƒãƒã—ãŸä»¶æ•°
excluded = 0        # é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸä»¶æ•°
duplicates = 0      # é‡è¤‡ã§ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸä»¶æ•°
created = 0         # æ–°è¦ä½œæˆã—ãŸIssueæ•°
failed = 0          # ä½œæˆå¤±æ•—ã—ãŸä»¶æ•°
```

## Phase 2: RSSå–å¾—ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ç›´æ¥å–å¾—ï¼‰

**é‡è¦**: å„ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯è‡ªåˆ†ã®æ‹…å½“ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ç›´æ¥è¨˜äº‹ã‚’å–å¾—ã—ã¾ã™ã€‚

### ã‚¹ãƒ†ãƒƒãƒ—2.1: æ‹…å½“ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ã®å–å¾—

```python
def fetch_assigned_feeds(assigned_feeds: list[dict]) -> list[dict]:
    """æ‹…å½“ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—ã™ã‚‹

    Parameters
    ----------
    assigned_feeds : list[dict]
        æ‹…å½“ãƒ•ã‚£ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆï¼ˆfeed_id, titleã‚’å«ã‚€ï¼‰

    Returns
    -------
    list[dict]
        å–å¾—ã—ãŸè¨˜äº‹ã®ãƒªã‚¹ãƒˆ
    """

    all_items = []

    for feed in assigned_feeds:
        feed_id = feed["feed_id"]
        feed_title = feed["title"]

        try:
            # Step 1: ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’æœ€æ–°åŒ–
            mcp__rss__fetch_feed(feed_id=feed_id)

            # Step 2: è¨˜äº‹ã‚’å–å¾—ï¼ˆ24æ™‚é–“ä»¥å†…ï¼‰
            items = mcp__rss__get_items(
                feed_id=feed_id,
                hours=24,
                limit=50
            )

            # ãƒ•ã‚£ãƒ¼ãƒ‰æƒ…å ±ã‚’ä»˜åŠ 
            for item in items:
                item["feed_source"] = feed_title
                item["feed_id"] = feed_id

            all_items.extend(items)
            ãƒ­ã‚°å‡ºåŠ›: f"å–å¾—å®Œäº†: {feed_title} ({len(items)}ä»¶)"

        except Exception as e:
            ãƒ­ã‚°å‡ºåŠ›: f"è­¦å‘Š: ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—å¤±æ•—: {feed_title}: {e}"
            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è©¦è¡Œ
            local_items = load_from_local(feed_id, feed_title)
            all_items.extend(local_items)

    return all_items
```

### ã‚¹ãƒ†ãƒƒãƒ—2.2: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

MCPãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ããªã„å ´åˆã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã•ã‚ŒãŸRSSãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```python
def load_from_local(feed_id: str, feed_title: str) -> list[dict]:
    """ãƒ­ãƒ¼ã‚«ãƒ«ã®RSSãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—ã™ã‚‹

    Parameters
    ----------
    feed_id : str
        ãƒ•ã‚£ãƒ¼ãƒ‰ID
    feed_title : str
        ãƒ•ã‚£ãƒ¼ãƒ‰åï¼ˆãƒ­ã‚°ç”¨ï¼‰

    Returns
    -------
    list[dict]
        å–å¾—ã—ãŸè¨˜äº‹ã®ãƒªã‚¹ãƒˆ
    """

    local_path = f"data/raw/rss/{feed_id}/items.json"

    try:
        with open(local_path) as f:
            data = json.load(f)

        items = data.get("items", [])

        # 24æ™‚é–“ä»¥å†…ã®ã‚¢ã‚¤ãƒ†ãƒ ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
        cutoff = datetime.now(timezone.utc) - timedelta(hours=24)
        recent_items = []

        for item in items:
            published = item.get("published")
            if published:
                try:
                    dt = datetime.fromisoformat(published.replace('Z', '+00:00'))
                    if dt >= cutoff:
                        item["feed_source"] = feed_title
                        item["feed_id"] = feed_id
                        recent_items.append(item)
                except ValueError:
                    continue

        ãƒ­ã‚°å‡ºåŠ›: f"ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰å–å¾—: {feed_title} ({len(recent_items)}ä»¶)"
        return recent_items

    except FileNotFoundError:
        ãƒ­ã‚°å‡ºåŠ›: f"è­¦å‘Š: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ãªã—: {local_path}"
        return []
    except json.JSONDecodeError as e:
        ãƒ­ã‚°å‡ºåŠ›: f"è­¦å‘Š: JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {local_path}: {e}"
        return []
```

## Phase 2.5: å…¬é–‹æ—¥æ™‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€å¿…é ˆã€‘

**é‡è¦**: `--since`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æŒ‡å®šã•ã‚ŒãŸæœŸé–“å†…ã®è¨˜äº‹ã®ã¿ã‚’å‡¦ç†å¯¾è±¡ã¨ã—ã¾ã™ã€‚

### ã‚¹ãƒ†ãƒƒãƒ—2.5.1: --sinceãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è§£æ

```python
def parse_since_param(since: str) -> int:
    """--sinceãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ—¥æ•°ã«å¤‰æ›

    Parameters
    ----------
    since : str
        æœŸé–“æŒ‡å®šï¼ˆä¾‹: "1d", "3d", "7d"ï¼‰

    Returns
    -------
    int
        æ—¥æ•°

    Examples
    --------
    >>> parse_since_param("1d")
    1
    >>> parse_since_param("3d")
    3
    >>> parse_since_param("7d")
    7
    """

    if since.endswith("d"):
        try:
            return int(since[:-1])
        except ValueError:
            pass

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1æ—¥
    return 1
```

### ã‚¹ãƒ†ãƒƒãƒ—2.5.2: å…¬é–‹æ—¥æ™‚ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

```python
from datetime import datetime, timedelta, timezone

def filter_by_published_date(
    items: list[dict],
    since_days: int,
) -> tuple[list[dict], int]:
    """å…¬é–‹æ—¥æ™‚ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

    Parameters
    ----------
    items : list[dict]
        RSSè¨˜äº‹ãƒªã‚¹ãƒˆ
    since_days : int
        ç¾åœ¨æ—¥æ™‚ã‹ã‚‰é¡ã‚‹æ—¥æ•°

    Returns
    -------
    tuple[list[dict], int]
        (ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®è¨˜äº‹ãƒªã‚¹ãƒˆ, æœŸé–“å¤–ã§ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸä»¶æ•°)

    Notes
    -----
    - published ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯è¨˜äº‹ã®å…¬é–‹æ—¥æ™‚ï¼ˆRSSã®pubDateï¼‰
    - published ãŒãªã„å ´åˆã¯ fetched_at ã§ä»£æ›¿åˆ¤å®š
    - ä¸¡æ–¹ãªã„å ´åˆã¯å‡¦ç†å¯¾è±¡ã«å«ã‚ã‚‹ï¼ˆé™¤å¤–ã—ãªã„ï¼‰
    """

    cutoff = datetime.now(timezone.utc) - timedelta(days=since_days)
    filtered = []
    skipped = 0

    for item in items:
        # å…¬é–‹æ—¥æ™‚ã‚’å–å¾—ï¼ˆpublished â†’ fetched_at ã®é †ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        date_str = item.get("published") or item.get("fetched_at")

        if not date_str:
            # æ—¥æ™‚æƒ…å ±ãŒãªã„å ´åˆã¯å‡¦ç†å¯¾è±¡ã«å«ã‚ã‚‹
            filtered.append(item)
            continue

        try:
            # ISO 8601å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
            dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))

            if dt >= cutoff:
                filtered.append(item)
            else:
                skipped += 1
                ãƒ­ã‚°å‡ºåŠ›: f"æœŸé–“å¤–ã‚¹ã‚­ãƒƒãƒ—: {item.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')} (å…¬é–‹: {date_str})"

        except ValueError:
            # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯å‡¦ç†å¯¾è±¡ã«å«ã‚ã‚‹
            filtered.append(item)

    ãƒ­ã‚°å‡ºåŠ›: f"å…¬é–‹æ—¥æ™‚ãƒ•ã‚£ãƒ«ã‚¿: {len(items)}ä»¶ â†’ {len(filtered)}ä»¶ (éå»{since_days}æ—¥ä»¥å†…)"
    return filtered, skipped
```

### ã‚¹ãƒ†ãƒƒãƒ—2.5.3: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ

å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯RSSå–å¾—å¾Œã€ãƒ†ãƒ¼ãƒåˆ¤å®šå‰ã«ä»¥ä¸‹ã‚’å®Ÿè¡Œ:

```python
# --since ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1dï¼‰
since_days = parse_since_param(args.get("since", "1d"))

# å…¬é–‹æ—¥æ™‚ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
items, date_skipped = filter_by_published_date(items, since_days)

# çµ±è¨ˆã«è¨˜éŒ²
stats["date_filtered"] = date_skipped
```

## Phase 3: AIåˆ¤æ–­ã«ã‚ˆã‚‹ãƒ†ãƒ¼ãƒåˆ†é¡

**é‡è¦**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã¯ä½¿ç”¨ã—ã¾ã›ã‚“ã€‚**AIãŒè¨˜äº‹ã®å†…å®¹ã‚’èª­ã¿å–ã‚Šã€ãƒ†ãƒ¼ãƒã«è©²å½“ã™ã‚‹ã‹åˆ¤æ–­**ã—ã¾ã™ã€‚

### ã‚¹ãƒ†ãƒƒãƒ—3.1: AIåˆ¤æ–­ã«ã‚ˆã‚‹ãƒ†ãƒ¼ãƒåˆ¤å®š

å„è¨˜äº‹ã«ã¤ã„ã¦ã€ã‚¿ã‚¤ãƒˆãƒ«ã¨è¦ç´„ï¼ˆsummaryï¼‰ã‚’èª­ã¿å–ã‚Šã€ä»¥ä¸‹ã®åŸºæº–ã§ãƒ†ãƒ¼ãƒã«è©²å½“ã™ã‚‹ã‹åˆ¤æ–­ã—ã¾ã™ã€‚

**ãƒ†ãƒ¼ãƒåˆ¥åˆ¤å®šåŸºæº–**:

| ãƒ†ãƒ¼ãƒ | åˆ¤å®šåŸºæº– |
|--------|----------|
| **Index** | æ ªä¾¡æŒ‡æ•°ï¼ˆæ—¥çµŒå¹³å‡ã€TOPIXã€S&P500ã€ãƒ€ã‚¦ã€ãƒŠã‚¹ãƒ€ãƒƒã‚¯ç­‰ï¼‰ã®å‹•å‘ã€å¸‚å ´å…¨ä½“ã®ä¸Šæ˜‡/ä¸‹è½ã€ETFé–¢é€£ |
| **Stock** | å€‹åˆ¥ä¼æ¥­ã®æ±ºç®—ç™ºè¡¨ã€æ¥­ç¸¾äºˆæƒ³ã€M&Aã€è²·åã€ææºã€æ ªå¼å…¬é–‹ã€çµŒå–¶é™£ã®å¤‰æ›´ |
| **Sector** | ç‰¹å®šæ¥­ç•Œï¼ˆéŠ€è¡Œã€ä¿é™ºã€è‡ªå‹•è»Šã€åŠå°ä½“ã€ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ç­‰ï¼‰ã®å‹•å‘ã€è¦åˆ¶å¤‰æ›´ |
| **Macro** | é‡‘èæ”¿ç­–ï¼ˆé‡‘åˆ©ã€é‡çš„ç·©å’Œï¼‰ã€ä¸­å¤®éŠ€è¡Œï¼ˆFedã€æ—¥éŠ€ã€ECBï¼‰ã€çµŒæ¸ˆæŒ‡æ¨™ï¼ˆGDPã€CPIã€é›‡ç”¨çµ±è¨ˆï¼‰ã€ç‚ºæ›¿ |
| **AI** | AIæŠ€è¡“ã€æ©Ÿæ¢°å­¦ç¿’ã€ç”ŸæˆAIã€AIä¼æ¥­ï¼ˆOpenAIã€NVIDIAç­‰ï¼‰ã€AIæŠ•è³‡ã€AIè¦åˆ¶ |

**åˆ¤å®šãƒ—ãƒ­ã‚»ã‚¹**:

```
[1] è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨è¦ç´„ã‚’èª­ã‚€
    â†“
[2] è¨˜äº‹ã®ä¸»é¡Œã‚’ç†è§£ã™ã‚‹
    â†“
[3] ä¸Šè¨˜ãƒ†ãƒ¼ãƒåˆ¤å®šåŸºæº–ã«ç…§ã‚‰ã—ã¦è©²å½“ã™ã‚‹ã‹åˆ¤æ–­
    â†“
[4] è©²å½“ã™ã‚‹å ´åˆ â†’ Phase 2.2ã¸
    è©²å½“ã—ãªã„å ´åˆ â†’ ã‚¹ã‚­ãƒƒãƒ—
```

**åˆ¤å®šä¾‹**:

| è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ« | AIã®åˆ¤æ–­ | ãƒ†ãƒ¼ãƒ |
|------------|---------|--------|
| "S&P 500 hits new record high amid tech rally" | æ ªä¾¡æŒ‡æ•°ã®å‹•å‘ã«ã¤ã„ã¦ â†’ è©²å½“ | Index |
| "Fed signals rate cut in March meeting" | é‡‘èæ”¿ç­–ãƒ»ä¸­å¤®éŠ€è¡Œã®å‹•å‘ â†’ è©²å½“ | Macro |
| "Apple reports Q4 earnings beat" | å€‹åˆ¥ä¼æ¥­ã®æ±ºç®—ç™ºè¡¨ â†’ è©²å½“ | Stock |
| "Banks face new capital requirements" | éŠ€è¡Œã‚»ã‚¯ã‚¿ãƒ¼ã®è¦åˆ¶ â†’ è©²å½“ | Sector |
| "OpenAI launches new model capabilities" | AIä¼æ¥­ã®å‹•å‘ â†’ è©²å½“ | AI |
| "Celebrity launches new clothing line" | é‡‘èãƒ»çµŒæ¸ˆã¨ç„¡é–¢ä¿‚ â†’ éè©²å½“ | - |

### ã‚¹ãƒ†ãƒƒãƒ—3.2: é™¤å¤–åˆ¤æ–­

ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªã«è©²å½“ã™ã‚‹è¨˜äº‹ã¯é™¤å¤–ã—ã¾ã™ï¼ˆé‡‘èãƒ†ãƒ¼ãƒã«é–¢é€£ã™ã‚‹å ´åˆã‚’é™¤ãï¼‰:

- **ã‚¹ãƒãƒ¼ãƒ„**: è©¦åˆçµæœã€é¸æ‰‹ç§»ç±ãªã©ï¼ˆãŸã ã—ã€ã‚¹ãƒãƒ¼ãƒ„é–¢é€£ä¼æ¥­ã®æ±ºç®—ç­‰ã¯å¯¾è±¡ï¼‰
- **ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ**: æ˜ ç”»ã€éŸ³æ¥½ã€èŠ¸èƒ½ãƒ‹ãƒ¥ãƒ¼ã‚¹
- **æ”¿æ²»**: é¸æŒ™ã€å†…é–£é–¢é€£ï¼ˆãŸã ã—ã€é‡‘èæ”¿ç­–ãƒ»è¦åˆ¶ã«é–¢é€£ã™ã‚‹å ´åˆã¯å¯¾è±¡ï¼‰
- **ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹**: äº‹æ•…ã€ç½å®³ã€çŠ¯ç½ª

### ã‚¹ãƒ†ãƒƒãƒ—3.3: é‡è¤‡ãƒã‚§ãƒƒã‚¯

```python
def calculate_title_similarity(title1: str, title2: str) -> float:
    """ã‚¿ã‚¤ãƒˆãƒ«ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ï¼ˆJaccardä¿‚æ•°ï¼‰"""

    words1 = set(title1.lower().split())
    words2 = set(title2.lower().split())

    if not words1 or not words2:
        return 0.0

    common = words1.intersection(words2)
    total = words1.union(words2)

    return len(common) / len(total)


def is_duplicate(new_item: dict, existing_issues: list[dict], threshold: float = 0.85) -> bool:
    """æ—¢å­˜Issueã¨é‡è¤‡ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""

    new_link = new_item.get('link', '')
    new_title = new_item.get('title', '')

    for issue in existing_issues:
        # URLå®Œå…¨ä¸€è‡´
        body = issue.get('body', '')
        if new_link and new_link in body:
            return True

        # ã‚¿ã‚¤ãƒˆãƒ«é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯
        issue_title = issue.get('title', '')
        similarity = calculate_title_similarity(new_title, issue_title)

        if similarity >= threshold:
            return True

    return False
```

## Phase 4: GitHubæŠ•ç¨¿

### ã‚¹ãƒ†ãƒƒãƒ—4.0: è¨˜äº‹å†…å®¹å–å¾—ã¨è¦ç´„ç”Ÿæˆã€æœ€é‡è¦ã€‘

> **ğŸš¨ ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯çµ¶å¯¾ã«çœç•¥ã—ãªã„ã§ãã ã•ã„ï¼ğŸš¨**
>
> RSSã®æ¦‚è¦ï¼ˆsummaryï¼‰ã ã‘ã§ã¯æƒ…å ±ãŒä¸ååˆ†ã§ã™ã€‚
> **å¿…ãšè¨˜äº‹URLã‹ã‚‰æœ¬æ–‡ã‚’å–å¾—**ã—ã¦è©³ç´°ãªæ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã€‚

**é‡è¦**: Issueä½œæˆå‰ã«ã€å¿…ãšè¨˜äº‹URLã‹ã‚‰å®Ÿéš›ã®å†…å®¹ã‚’å–å¾—ã—ã¦æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã€‚

#### 4.0.1: è¨˜äº‹æœ¬æ–‡ã®å–å¾—

**WebFetchãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨**ã—ã¦è¨˜äº‹URLã‹ã‚‰æœ¬æ–‡ã‚’å–å¾—ã—ã¾ã™ã€‚

```python
def fetch_article_content(url: str, title: str) -> str:
    """è¨˜äº‹å†…å®¹ã‚’å–å¾—ï¼ˆWebFetchå¿…é ˆï¼‰

    Parameters
    ----------
    url : str
        è¨˜äº‹ã®URL
    title : str
        è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ç”¨ï¼‰

    Returns
    -------
    str
        å–å¾—ã—ãŸè¨˜äº‹å†…å®¹

    Notes
    -----
    WebFetchãƒ„ãƒ¼ãƒ«ã¯è¨˜äº‹URLã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã€HTMLâ†’Markdownã«å¤‰æ›ã—ã¦
    å†…å®¹ã‚’æŠ½å‡ºã—ã¾ã™ã€‚AIãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†ã•ã‚Œã‚‹ãŸã‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§
    ã©ã®ã‚ˆã†ãªæƒ…å ±ã‚’æŠ½å‡ºã—ãŸã„ã‹ã‚’æŒ‡å®šã§ãã¾ã™ã€‚
    """

    # WebFetchã§è¨˜äº‹æœ¬æ–‡ã‚’å–å¾—
    content = WebFetch(
        url=url,
        prompt="""ã“ã®é‡‘èãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®æœ¬æ–‡ã‚’è©³ã—ãè¦ç´„ã—ã¦ãã ã•ã„ã€‚

å¿…ãšä»¥ä¸‹ã®æƒ…å ±ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
1. **ä¸»è¦ãªäº‹å®Ÿ**: ä½•ãŒèµ·ããŸã®ã‹ã€èª°ãŒé–¢ä¸ã—ã¦ã„ã‚‹ã‹
2. **æ•°å€¤ãƒ‡ãƒ¼ã‚¿**: æ ªä¾¡ã€æŒ‡æ•°ã®å¤‰å‹•ç‡ã€é‡‘é¡ã€æœŸé–“ãªã©å…·ä½“çš„ãªæ•°å­—
3. **èƒŒæ™¯ãƒ»ç†ç”±**: ãªãœã“ã®å‡ºæ¥äº‹ãŒèµ·ããŸã®ã‹ã€ã©ã®ã‚ˆã†ãªçµŒç·¯ã‹
4. **å¸‚å ´ã¸ã®å½±éŸ¿**: å¸‚å ´ã€æ¥­ç•Œã€æŠ•è³‡å®¶ã¸ã®å½±éŸ¿ã¯ä½•ã‹
5. **ä»Šå¾Œã®å±•æœ›**: ã‚¢ãƒŠãƒªã‚¹ãƒˆã‚„å°‚é–€å®¶ã®è¦‹é€šã—ã€äºˆæ¸¬
6. **é–¢é€£ä¼æ¥­ãƒ»æ©Ÿé–¢**: è¨€åŠã•ã‚Œã¦ã„ã‚‹ä¼æ¥­åã€æ”¿åºœæ©Ÿé–¢ã€ä¸­å¤®éŠ€è¡Œãªã©

é‡è¦ãªæ•°å­—ã‚„å›ºæœ‰åè©ã¯å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚
æ¨æ¸¬ã§ã¯ãªãã€è¨˜äº‹ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹äº‹å®Ÿã®ã¿ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚"""
    )
    return content
```

**å®Ÿè¡Œä¾‹**:
```
WebFetch(
    url="https://www.cnbc.com/2026/01/19/sp-500-hits-new-record.html",
    prompt="ã“ã®é‡‘èãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®æœ¬æ–‡ã‚’è©³ã—ãè¦ç´„ã—ã¦ãã ã•ã„..."
)

â†’ çµæœ: "S&P500æŒ‡æ•°ã¯2026å¹´1æœˆ19æ—¥ã€çµ‚å€¤ã§5,200ãƒã‚¤ãƒ³ãƒˆã‚’è¨˜éŒ²ã—ã€
   éå»æœ€é«˜å€¤ã‚’æ›´æ–°ã—ãŸã€‚ãƒ†ãƒƒã‚¯æ ªã®ä¸Šæ˜‡ãŒç‰½å¼•ã—ã€ç‰¹ã«NVIDIAï¼ˆ+5.2%ï¼‰ã€
   Appleï¼ˆ+2.1%ï¼‰ãŒå¤§ããè²¢çŒ®ã€‚FRBã®åˆ©ä¸‹ã’è¦³æ¸¬ãŒ..."
```

#### 4.0.2: æ—¥æœ¬èªè¦ç´„ã®ç”Ÿæˆ

å–å¾—ã—ãŸè¨˜äº‹å†…å®¹ã‹ã‚‰ã€**æŠ•è³‡åˆ¤æ–­ã«å½¹ç«‹ã¤400å­—ä»¥ä¸Šã®æ—¥æœ¬èªè¦ç´„**ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

```python
def generate_japanese_summary(article_content: str, rss_title: str, rss_summary: str) -> str:
    """è¨˜äº‹å†…å®¹ã‹ã‚‰æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆï¼ˆ400å­—ä»¥ä¸Šï¼‰

    Parameters
    ----------
    article_content : str
        WebFetchã§å–å¾—ã—ãŸè¨˜äº‹æœ¬æ–‡
    rss_title : str
        RSSã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè‹±èªã®å ´åˆã‚ã‚Šï¼‰
    rss_summary : str
        RSSã®æ¦‚è¦ï¼ˆè£œè¶³æƒ…å ±ã¨ã—ã¦ä½¿ç”¨ï¼‰

    Returns
    -------
    str
        æ—¥æœ¬èªè¦ç´„ï¼ˆ400å­—ä»¥ä¸Šï¼‰
    """

    # æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆ
    summary = f"""ã€è¦ç´„ã€‘

{article_content}

---
**è£œè¶³æƒ…å ±**:
- å…ƒè¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {rss_title}
- RSSæ¦‚è¦: {rss_summary}
"""
    return summary
```

**è¦ç´„ã«å«ã‚ã‚‹ã¹ãæƒ…å ±**:
| é …ç›® | å¿…é ˆåº¦ | ä¾‹ |
|-----|-------|-----|
| ä¸»è¦äº‹å®Ÿ | å¿…é ˆ | ã€ŒS&P500ãŒéå»æœ€é«˜å€¤ã‚’æ›´æ–°ã€ |
| æ•°å€¤ãƒ‡ãƒ¼ã‚¿ | å¿…é ˆ | ã€Œ5,200ãƒã‚¤ãƒ³ãƒˆï¼ˆ+1.2%ï¼‰ã€ |
| èƒŒæ™¯ãƒ»ç†ç”± | å¿…é ˆ | ã€ŒFRBã®åˆ©ä¸‹ã’è¦³æ¸¬ãŒè¿½ã„é¢¨ã«ã€ |
| å½±éŸ¿ | æ¨å¥¨ | ã€Œãƒ†ãƒƒã‚¯æ ªãŒå¸‚å ´ã‚’ç‰½å¼•ã€ |
| ä»Šå¾Œã®å±•æœ› | æ¨å¥¨ | ã€Œã‚¢ãƒŠãƒªã‚¹ãƒˆã¯å¹´å†…ã•ã‚‰ãªã‚‹ä¸Šæ˜‡ã‚’äºˆæ¸¬ã€ |
| é–¢é€£ä¼æ¥­ | ã‚ã‚Œã° | ã€ŒNVIDIAã€Appleã€Microsoftã€ |

#### 4.0.3: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†

WebFetchãŒå¤±æ•—ã—ãŸå ´åˆï¼ˆãƒšã‚¤ã‚¦ã‚©ãƒ¼ãƒ«ã€ã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦ãªã©ï¼‰ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:

```python
def fetch_with_fallback(url: str, title: str, rss_summary: str) -> str:
    """è¨˜äº‹å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰"""

    try:
        # 1. WebFetchã§è¨˜äº‹å–å¾—ã‚’è©¦è¡Œ
        content = WebFetch(url=url, prompt="...")
        if content and len(content) > 100:
            return content
    except Exception as e:
        ãƒ­ã‚°å‡ºåŠ›: f"WebFetchå¤±æ•—: {url} - {e}"

    # 2. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: RSSã®æƒ…å ± + Webæ¤œç´¢è£œå®Œ
    # gemini-search ã‚¹ã‚­ãƒ«ã‚’ä½¿ç”¨
    try:
        search_query = f"{title} é‡‘èãƒ‹ãƒ¥ãƒ¼ã‚¹"
        search_result = Skill("gemini-search", args=search_query)
        return f"""ã€RSSæƒ…å ±ã€‘
{rss_summary}

ã€Webæ¤œç´¢ã«ã‚ˆã‚‹è£œè¶³ã€‘
{search_result}
"""
    except Exception as e:
        ãƒ­ã‚°å‡ºåŠ›: f"Webæ¤œç´¢ã‚‚å¤±æ•—: {e}"

    # 3. æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: RSSã®æƒ…å ±ã®ã¿ï¼ˆè­¦å‘Šä»˜ãï¼‰
    return f"""âš ï¸ è¨˜äº‹æœ¬æ–‡ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚RSSã®æ¦‚è¦ã®ã¿:

{rss_summary}

---
æ³¨æ„: è©³ç´°ã¯å…ƒè¨˜äº‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„: {url}
"""
```

**é‡è¦**: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã§ã‚‚ã€å–å¾—ã§ãã‚‹æƒ…å ±ã¯æœ€å¤§é™æ´»ç”¨ã™ã‚‹ã“ã¨ã€‚

### ã‚¹ãƒ†ãƒƒãƒ—4.1: æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé–¢æ•°

**é‡è¦**: GitHub Projectã§ã‚½ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã€å…¬é–‹æ—¥æ™‚ã‚’ISO 8601å½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚
ã¾ãŸã€Issueæœ¬æ–‡ã«ã¯ã€Œåé›†æ—¥æ™‚ã€ï¼ˆIssueä½œæˆæ™‚ã®æ—¥æ™‚ï¼‰ã‚‚å¿…ãšè¨˜è¼‰ã—ã¾ã™ã€‚

```python
from datetime import datetime, timezone
import pytz


def format_published_iso(published_str: str | None) -> str:
    """å…¬é–‹æ—¥ã‚’ISO 8601å½¢å¼ã«å¤‰æ›ï¼ˆYYYY-MM-DDï¼‰"""

    if not published_str:
        # å…¬é–‹æ—¥ãŒãªã„å ´åˆã¯ç¾åœ¨æ—¥æ™‚ã‚’ä½¿ç”¨
        return datetime.now(timezone.utc).strftime('%Y-%m-%d')

    try:
        dt = datetime.fromisoformat(published_str.replace('Z', '+00:00'))
    except ValueError:
        # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯ç¾åœ¨æ—¥æ™‚ã‚’ä½¿ç”¨
        dt = datetime.now(timezone.utc)

    # Dateå‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯YYYY-MM-DDå½¢å¼
    return dt.strftime('%Y-%m-%d')


def format_published_jst(published_str: str | None) -> str:
    """å…¬é–‹æ—¥ã‚’JST YYYY-MM-DD HH:MMå½¢å¼ã«å¤‰æ›ï¼ˆIssueæœ¬æ–‡ç”¨ï¼‰"""

    jst = pytz.timezone('Asia/Tokyo')

    if not published_str:
        # å…¬é–‹æ—¥ãŒãªã„å ´åˆã¯ç¾åœ¨æ—¥æ™‚ã‚’ä½¿ç”¨
        return datetime.now(jst).strftime('%Y-%m-%d %H:%M')

    try:
        dt = datetime.fromisoformat(published_str.replace('Z', '+00:00'))
    except ValueError:
        # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯ç¾åœ¨æ—¥æ™‚ã‚’ä½¿ç”¨
        dt = datetime.now(timezone.utc)

    dt_jst = dt.astimezone(jst)
    return dt_jst.strftime('%Y-%m-%d %H:%M')


def get_collected_at_jst() -> str:
    """åé›†æ—¥æ™‚ï¼ˆç¾åœ¨æ™‚åˆ»ï¼‰ã‚’JSTå½¢å¼ã§å–å¾—ï¼ˆYYYY-MM-DD HH:MMï¼‰

    Issueä½œæˆæ™‚ã«å‘¼ã³å‡ºã—ã€åé›†æ—¥æ™‚ã¨ã—ã¦è¨˜éŒ²ã™ã‚‹ã€‚
    """

    jst = pytz.timezone('Asia/Tokyo')
    return datetime.now(jst).strftime('%Y-%m-%d %H:%M')
```

### ã‚¹ãƒ†ãƒƒãƒ—4.2: Issueä½œæˆï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿æ–¹å¼ï¼‰

**é‡è¦: Issueã‚¿ã‚¤ãƒˆãƒ«ã®æ—¥æœ¬èªåŒ–ãƒ«ãƒ¼ãƒ«**:
1. **ã‚¿ã‚¤ãƒˆãƒ«å½¢å¼**: `[{theme_ja}] {japanese_title}`
2. **ãƒ†ãƒ¼ãƒåãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆæ—¥æœ¬èªï¼‰**:
   - `[æ ªä¾¡æŒ‡æ•°]`, `[å€‹åˆ¥éŠ˜æŸ„]`, `[ã‚»ã‚¯ã‚¿ãƒ¼]`, `[ãƒã‚¯ãƒ­çµŒæ¸ˆ]`, `[AI]`
3. **ã‚¿ã‚¤ãƒˆãƒ«ç¿»è¨³**: è‹±èªè¨˜äº‹ã®å ´åˆã¯æ—¥æœ¬èªã«ç¿»è¨³ï¼ˆè¦ç´„ç”Ÿæˆæ™‚ã«åŒæ™‚ã«å®Ÿæ–½ï¼‰

**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿â†’ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç½®æ›**:

```bash
# Step 1: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€
template=$(cat .github/ISSUE_TEMPLATE/news-article.md | tail -n +7)  # frontmatteré™¤å¤–

# Step 2: åé›†æ—¥æ™‚ã‚’å–å¾—ï¼ˆIssueä½œæˆç›´å‰ã«å®Ÿè¡Œï¼‰
collected_at=$(TZ=Asia/Tokyo date '+%Y-%m-%d %H:%M')

# Step 3: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç½®æ›
body="${template//\{\{summary\}\}/$japanese_summary}"
body="${body//\{\{url\}\}/$link}"
body="${body//\{\{published_date\}\}/$published_jst(JST)}"
body="${body//\{\{collected_at\}\}/$collected_at(JST)}"
body="${body//\{\{credibility\}\}/3ç‚¹ - ä¸­ç¨‹åº¦}"
body="${body//\{\{category\}\}/$category}"
body="${body//\{\{feed_source\}\}/$source}"
body="${body//\{\{priority\}\}/Medium - é€šå¸¸ã®è¨˜äº‹åŒ–å€™è£œ}"
body="${body//\{\{notes\}\}/- ãƒ†ãƒ¼ãƒ: $theme_name
- AIåˆ¤å®šç†ç”±: $åˆ¤å®šç†ç”±}"

# Step 4: Issueä½œæˆï¼ˆclosedçŠ¶æ…‹ã§ä½œæˆï¼‰
issue_url=$(gh issue create \
    --repo YH-05/finance \
    --title "[{theme_ja}] {japanese_title}" \
    --body "$body" \
    --label "news")

# Issueç•ªå·ã‚’æŠ½å‡º
issue_number=$(echo "$issue_url" | grep -oE '[0-9]+$')

# Step 5: Issueã‚’closeã™ã‚‹ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹Issueã¯closedçŠ¶æ…‹ã§ä¿å­˜ï¼‰
gh issue close "$issue_number" --repo YH-05/finance
```

**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ä¸€è¦§** (`.github/ISSUE_TEMPLATE/news-article.md`):

| ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ | èª¬æ˜ | ä¾‹ |
|-----------------|------|-----|
| `{{summary}}` | æ—¥æœ¬èªè¦ç´„ï¼ˆ400å­—ä»¥ä¸Šï¼‰ | - |
| `{{url}}` | æƒ…å ±æºURL | `https://...` |
| `{{published_date}}` | å…¬é–‹æ—¥æ™‚ | `2026-01-15 10:00(JST)` |
| `{{collected_at}}` | åé›†æ—¥æ™‚ | `2026-01-15 14:30(JST)` |
| `{{credibility}}` | ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ | `3ç‚¹ - ä¸­ç¨‹åº¦` |
| `{{category}}` | ã‚«ãƒ†ã‚´ãƒª | `Indexï¼ˆæ ªä¾¡æŒ‡æ•°ï¼‰` |
| `{{feed_source}}` | ãƒ•ã‚£ãƒ¼ãƒ‰å | `CNBC - Markets` |
| `{{priority}}` | å„ªå…ˆåº¦ | `Medium - é€šå¸¸ã®è¨˜äº‹åŒ–å€™è£œ` |
| `{{notes}}` | å‚™è€ƒãƒ»ãƒ¡ãƒ¢ | ãƒ†ãƒ¼ãƒã€AIåˆ¤å®šç†ç”± |

### ã‚¹ãƒ†ãƒƒãƒ—4.3: Projectè¿½åŠ 

```bash
gh project item-add 15 \
    --owner YH-05 \
    --url {issue_url}
```

### ã‚¹ãƒ†ãƒƒãƒ—4.4: Statusè¨­å®šï¼ˆGraphQL APIï¼‰

**Step 1: Issue Node IDã‚’å–å¾—**

```bash
gh api graphql -f query='
query {
  repository(owner: "YH-05", name: "finance") {
    issue(number: {issue_number}) {
      id
    }
  }
}'
```

**Step 2: Project Item IDã‚’å–å¾—**

```bash
gh api graphql -f query='
query {
  node(id: "{issue_node_id}") {
    ... on Issue {
      projectItems(first: 10) {
        nodes {
          id
          project {
            number
          }
        }
      }
    }
  }
}'
```

**Step 3: Statusãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¨­å®š**

```bash
gh api graphql -f query='
mutation {
  updateProjectV2ItemFieldValue(
    input: {
      projectId: "PVT_kwHOBoK6AM4BMpw_"
      itemId: "{project_item_id}"
      fieldId: "PVTSSF_lAHOBoK6AM4BMpw_zg739ZE"
      value: {
        singleSelectOptionId: "{status_option_id}"
      }
    }
  ) {
    projectV2Item {
      id
    }
  }
}'
```

**âš ï¸ æ³¨æ„: ã‚¹ãƒ†ãƒƒãƒ—4.4å®Œäº†å¾Œã€å¿…ãšç¶šã‘ã¦ã‚¹ãƒ†ãƒƒãƒ—4.5ï¼ˆå…¬é–‹æ—¥æ™‚è¨­å®šï¼‰ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ï¼**

### ã‚¹ãƒ†ãƒƒãƒ—4.5: å…¬é–‹æ—¥æ™‚ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¨­å®šï¼ˆDateå‹ï¼‰ã€å¿…é ˆãƒ»æœ€é‡è¦ã€‘

> **ğŸš¨ çµ¶å¯¾ã«çœç•¥ã—ãªã„ã§ãã ã•ã„ï¼ğŸš¨**
>
> ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’çœç•¥ã™ã‚‹ã¨ã€GitHub Projectã§ã€ŒNo dateã€ã¨è¡¨ç¤ºã•ã‚Œã€
> è¨˜äº‹ã®æ™‚ç³»åˆ—ç®¡ç†ãŒã§ããªããªã‚Šã¾ã™ã€‚

**âš ï¸ å¿…é ˆ**: ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’çœç•¥ã™ã‚‹ã¨GitHub Projectã§ã€ŒNo dateã€ã¨è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
**âš ï¸ å¿…é ˆ**: Issueä½œæˆå¾Œã€Statusè¨­å®šã¨å…±ã«å¿…ãšå®Ÿè¡Œã™ã‚‹ã“ã¨ã€‚
**âš ï¸ ç¢ºèª**: å®Ÿè¡Œå¾Œã€GitHub Projectä¸Šã§æ—¥ä»˜ãŒæ­£ã—ãè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã€‚

GitHub Projectã§Issueã‚’å…¬é–‹æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã€å¿…ãšè¨­å®šã—ã¦ãã ã•ã„ã€‚

```bash
gh api graphql -f query='
mutation {
  updateProjectV2ItemFieldValue(
    input: {
      projectId: "PVT_kwHOBoK6AM4BMpw_"
      itemId: "{project_item_id}"
      fieldId: "PVTF_lAHOBoK6AM4BMpw_zg8BzrI"
      value: {
        date: "{published_iso}"
      }
    }
  ) {
    projectV2Item {
      id
    }
  }
}'
```

**æ—¥ä»˜å½¢å¼**: `YYYY-MM-DD`ï¼ˆä¾‹: `2026-01-15`ï¼‰

## Phase 5: çµæœå ±å‘Š

### çµ±è¨ˆã‚µãƒãƒªãƒ¼å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

```markdown
## {theme_name} ãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†å®Œäº†

### å‡¦ç†çµ±è¨ˆ
- **å‡¦ç†è¨˜äº‹æ•°**: {processed}ä»¶
- **ãƒ†ãƒ¼ãƒãƒãƒƒãƒ**: {matched}ä»¶ï¼ˆAIåˆ¤æ–­ï¼‰
- **é‡è¤‡**: {duplicates}ä»¶
- **æ–°è¦æŠ•ç¨¿**: {created}ä»¶
- **æŠ•ç¨¿å¤±æ•—**: {failed}ä»¶

### æŠ•ç¨¿ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹

1. **{title}** [#{issue_number}]
   - ã‚½ãƒ¼ã‚¹: {source}
   - å…¬é–‹æ—¥æ™‚: {published_jst}
   - AIåˆ¤å®šç†ç”±: {åˆ¤å®šç†ç”±}
   - URL: https://github.com/YH-05/finance/issues/{issue_number}
```

## ãƒ†ãƒ¼ãƒåˆ¥Status IDä¸€è¦§

| ãƒ†ãƒ¼ãƒ | Statuså | Option ID |
|--------|----------|-----------|
| index | Index | `f75ad846` |
| stock | Stock | `47fc9ee4` |
| sector | Sector | `98236657` |
| macro | Macro Economics | `c40731f6` |
| ai | AI | `17189c86` |

## GitHub Projectãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸€è¦§

| ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å | ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ID | å‹ | ç”¨é€” |
|-------------|-------------|-----|------|
| Status | `PVTSSF_lAHOBoK6AM4BMpw_zg739ZE` | SingleSelect | ãƒ†ãƒ¼ãƒåˆ†é¡ |
| å…¬é–‹æ—¥æ™‚ | `PVTF_lAHOBoK6AM4BMpw_zg8BzrI` | Date | ã‚½ãƒ¼ãƒˆç”¨ |

## å…±é€šã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### E001: MCPãƒ„ãƒ¼ãƒ«æ¥ç¶šã‚¨ãƒ©ãƒ¼

```python
def handle_mcp_error(feed_id: str, feed_title: str, error: Exception) -> list[dict]:
    """MCPãƒ„ãƒ¼ãƒ«æ¥ç¶šå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†

    Parameters
    ----------
    feed_id : str
        ãƒ•ã‚£ãƒ¼ãƒ‰ID
    feed_title : str
        ãƒ•ã‚£ãƒ¼ãƒ‰åï¼ˆãƒ­ã‚°ç”¨ï¼‰
    error : Exception
        ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼

    Returns
    -------
    list[dict]
        ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰å–å¾—ã—ãŸè¨˜äº‹ï¼ˆå–å¾—ã§ããªã„å ´åˆã¯ç©ºãƒªã‚¹ãƒˆï¼‰
    """

    ãƒ­ã‚°å‡ºåŠ›: f"è­¦å‘Š: MCPãƒ„ãƒ¼ãƒ«æ¥ç¶šå¤±æ•—: {feed_title}"
    ãƒ­ã‚°å‡ºåŠ›: f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {error}"
    ãƒ­ã‚°å‡ºåŠ›: "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è©¦è¡Œã—ã¾ã™"

    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
    return load_from_local(feed_id, feed_title)
```

### E002: Issueä½œæˆã‚¨ãƒ©ãƒ¼

```python
try:
    result = subprocess.run(
        ["gh", "issue", "create", ...],
        capture_output=True,
        text=True,
        check=True
    )
except subprocess.CalledProcessError as e:
    ãƒ­ã‚°å‡ºåŠ›: f"è­¦å‘Š: Issueä½œæˆå¤±æ•—: {item['title']}"
    ãƒ­ã‚°å‡ºåŠ›: f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e.stderr}"

    if "rate limit" in str(e.stderr).lower():
        ãƒ­ã‚°å‡ºåŠ›: "GitHub API ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚1æ™‚é–“å¾…æ©Ÿã—ã¦ãã ã•ã„ã€‚"

    failed += 1
    continue
```

### E003: å…¬é–‹æ—¥æ™‚è¨­å®šã‚¨ãƒ©ãƒ¼

```python
try:
    result = subprocess.run(
        ["gh", "api", "graphql", "-f", f"query={mutation}"],
        capture_output=True,
        text=True,
        check=True
    )
except subprocess.CalledProcessError as e:
    ãƒ­ã‚°å‡ºåŠ›: f"è­¦å‘Š: å…¬é–‹æ—¥æ™‚è¨­å®šå¤±æ•—: Issue #{issue_number}"
    ãƒ­ã‚°å‡ºåŠ›: f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e.stderr}"
    ãƒ­ã‚°å‡ºåŠ›: "Issueä½œæˆã¯æˆåŠŸã—ã¦ã„ã¾ã™ã€‚æ‰‹å‹•ã§å…¬é–‹æ—¥æ™‚ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    continue
```

## å‚è€ƒè³‡æ–™

- **Issueãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**: `.github/ISSUE_TEMPLATE/news-article.md`ï¼ˆMarkdownå½¢å¼ï¼‰
- **ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼**: `.claude/agents/finance-news-orchestrator.md`
- **ã‚³ãƒãƒ³ãƒ‰**: `.claude/commands/collect-finance-news.md`
- **GitHub Project**: https://github.com/users/YH-05/projects/15
