# Dify設計議論

> 作成日: 2026-02-13
> 前提: [Phase 0 設計メモ](phase0_philosophy_injection_design.md)（議論4: ハイブリッド構成、議論7: 4ステップワークフロー）
> 上位文書: [CAGR推定フレームワーク](cagr_estimation_framework.md)

---

## 論点A: KYの投資哲学をどのように「素材」として用意するか

### 背景

議論4で決定したハイブリッド構成を具体化する。

### A-1: システムプロンプト（常時注入）

LLMノードの指示に直接書く部分:

| 内容 | トークン量（目安） |
|------|-------------------|
| ゲートキーパー: ルール9, 3（定義＋具体例） | ~300 |
| 評価の枠組み: ルール5（+確度統合補足）, 12 | ~300 |
| 「ナレッジを必ず参照せよ」の指示 | ~50 |
| 構造化出力フォーマット指定 | ~200 |
| **合計** | **~850** |

### A-2: ナレッジベース（RAG検索）

Difyのナレッジに入れるドキュメント群:

| ドキュメント | チャンク単位 | 想定チャンク数 |
|-------------|-------------|---------------|
| 優位性の定義ルール（1+ブランド補足, 2, 6, 8）各ルールに具体例付き | ルール単位 | 4 |
| 裏付けの質ルール（4, 7, 10, 11）各ルールに具体例付き | ルール単位 | 4 |
| 却下パターン A〜G（各パターンに具体例付き） | パターン単位 | 7 |
| 高評価パターン I〜V（各パターンに具体例付き） | パターン単位 | 5 |
| KY評価付きfew-shot（ORLY, COST, MNST等） | 銘柄単位 | 3〜5 |
| **合計** | | **23〜25** |

### 設計判断

| # | 判断事項 | 選択肢 | 結論 |
|---|---------|--------|------|
| 1 | チャンク粒度 | a) ルール+具体例を1チャンク / b) ルールと具体例を分離 | **a) 1チャンクにまとめる** |
| 2 | few-shot例の構造化 | a) 銘柄単位 / b) 主張単位 | **a) 銘柄単位** |
| 3 | ナレッジベース分割 | a) 1つに統合 / b) 機能別に分割（ルール集/パターン集/few-shot集） | **b) 機能別に3分割（KB1:ルール集, KB2:パターン集, KB3:few-shot集）** |

---

## 論点B: 知識検索ノードの使い方

### 背景

Difyの知識検索ノードの設定を決定する。ナレッジベースのチャンク総数は23〜25個。

### 設定項目

| 設定 | 選択肢 | 結論 |
|------|--------|------|
| 検索方式 | ベクトル検索 / 全文検索 / ハイブリッド | |
| Top-K | 取得するチャンク数 | |
| スコア閾値 | 類似度の下限 | |
| リランク | Rerankモデル使用の有無 | |

### 設計判断

| # | 判断事項 | 選択肢 | 結論 |
|---|---------|--------|------|
| 4 | 検索クエリ設計 | a) ユーザー入力（主張テキスト）を直接検索クエリにする / b) LLMで検索クエリを生成させる | **a) 主張テキストを直接** |
| 5 | Top-K | チャンク総数23〜25に対して何件取得するか | **ステップ2: 5件（KB1+KB3, 13チャンク中）/ ステップ4: 4件（KB2, 12チャンク中）** |
| 6 | 常時取得 vs 動的取得 | a) 全ルール注入 / b) RAG依存 / c) 折衷案 | **b) RAG依存 + 一覧表による緩和。ルール定義のみ(~200トークン)をシステムプロンプトに目次として配置、詳細はRAG** |

---

## 論点C: Difyワークフロー全体設計

### 背景

議論7の4ステップ（主張抽出→構造化出力→ファクトチェック→検証エージェント）をDifyのノードにマッピングする。

### ワークフロー案

#### 案1: 単一ワークフロー（直列）

```
入力 → [知識検索] → [LLM: 主張抽出+ルール適用+構造化出力]
     → [LLM: ファクトチェック] → [LLM: 検証エージェント] → 出力
```

#### 案2: 分離ワークフロー（生成と検証を分離）

```
ワークフロー1（生成）:
  入力 → [知識検索] → [LLM: 主張抽出] → [LLM: ルール適用+構造化出力]
       → [LLM: ファクトチェック] → 中間出力

ワークフロー2（検証）:
  中間出力 → [知識検索: 却下パターン] → [LLM: 検証エージェント] → 最終出力
```

### 設計判断

| # | 判断事項 | 選択肢 | 結論 |
|---|---------|--------|------|
| 7 | ワークフロー分割 | a) 単一直列 / b) 生成と検証を分離 | **a) 単一ワークフロー** |
| 8 | ステップ間データ形式 | a) 構造化JSON / b) Markdown | **a) 構造化JSON** |
| 9 | 入力方式 | a) ファイルアップロード / b) テキスト / c) ナレッジベース | **a)+c) レポートはファイルアップロード、10-K/10-QはナレッジベースKB4** |

---

## 設計判断サマリー

| # | 判断事項 | 選択肢 | 結論 |
|---|---------|--------|------|
| 1 | チャンク粒度 | a) ルール+具体例を1チャンク / b) 分離 | **a) 1チャンクにまとめる** |
| 2 | few-shot例の構造化 | a) 銘柄単位 / b) 主張単位 | **a) 銘柄単位** |
| 3 | ナレッジベース分割 | a) 1つに統合 / b) 機能別に分割 | **b) 機能別に3分割** |
| 4 | 検索クエリ設計 | a) ユーザー入力直接 / b) LLMでクエリ生成 | **a) 主張テキストを直接** |
| 5 | Top-K | 取得チャンク数 | **ステップ2: 5 / ステップ4: 4** |
| 6 | 常時取得 vs 動的取得 | a) 全ルール注入 / b) RAG依存 / c) 折衷案 | **b) RAG依存 + 一覧表緩和** |
| 7 | ワークフロー分割 | a) 単一直列 / b) 生成と検証を分離 | **a) 単一ワークフロー** |
| 8 | ステップ間データ形式 | a) 構造化JSON / b) Markdown | **a) 構造化JSON** |
| 9 | 入力方式 | a) ファイルアップロード / b) テキスト / c) ナレッジベース | |
| 10 | 分類フレームワーク | a) Seven Powers等の外部フレームワーク / b) KYの評価軸 / c) 分類軸なしで開始 | **c) descriptive_labelで開始。KYの固有分類軸はフィードバック蓄積後に導入** |
| 11 | claim_typeの種別 | 3種別 | **competitive_advantage / cagr_connection / factual_claim** |
| 12 | ファクトチェック失敗時の処理 | a) 破棄 / b) アノテーションのみ | **b) アノテーションのみ。主張は破棄しない** |
| 13 | レポート生成・検証 | ステップ5(レポート生成)+ステップ6(レポート検証)を追加 | **追加。ステップ6はKB1+KB2を参照しJSON整合+KYルール整合+パターン整合を検証** |

---

## 議論ログ

### 議論A-1: 分類フレームワークの選定

#### 検討事項

| 方式 | 内容 | 採否 |
|------|------|------|
| A: 市場標準フレームワーク（Seven Powers等） | 外部フレームワークで主張を分類 | **不採用** |
| B: KYの評価軸で分類 | KYの12ルールをカテゴリとして使用 | **不採用**（12ルールは評価基準であり分類体系ではない） |
| **C: 分類軸なしで開始 → フィードバックから浮かび上がらせる** | `descriptive_label`（記述的ラベル）で開始し、KYの固有分類軸はフィードバック蓄積後に導入 | **採用** |

#### 確立された原則

> **分類体系はフィードバックループの「出力」であり、外部から注入する「入力」ではない。**
> 議論1の原則「ルール体系の範囲 = KYの暗黙知の表出のみ」を分類軸にも適用する。
> Seven Powersなどの外部フレームワークを分類軸として導入することは、KYの判断ではなく外部の判断軸を注入することにあたり、KYがアンカリングされる副作用がある。

#### KYの分類軸が浮かび上がるプロセス

```
PoC v1: 分類軸なし（descriptive_labelのみ）
  ↓
KYのフィードバック蓄積（5〜10銘柄分）
  ↓
分析: KYが高評価/低評価した主張を横断的に見る
  ↓
パターン発見 → KY固有の分類軸を仮説化
  ↓
KYに確認 → 分類軸として確定
  ↓
PoC v2: KY固有の分類軸を導入
```

#### 先行例

ブランド力4類型（Phase 0 議論3）は、KYのフィードバックから自然発生的に浮かび上がった分類軸の萌芽。このプロセスを意図的に繰り返す。

---

### 議論A-2: ステップ間データ形式

#### 結論

**構造化JSON**で確定。理由:

- 知識検索のクエリにフィールド値を使える
- クロスセクション比較が容易
- ステップ間でLLMが再パースする必要がない
- 検証エージェントがパターンマッチングしやすい

---

### 議論A-3: 構造化出力のJSONスキーマ

#### 確定事項

| 項目 | 決定 |
|------|------|
| 分類フレームワーク | 外部フレームワーク不使用。`descriptive_label`（記述的ラベル）で開始 |
| ステップ間データ形式 | 構造化JSON |
| `claim_type` の種別 | **3種別: `competitive_advantage`, `cagr_connection`, `factual_claim`** |
| ファクトチェック失敗時の処理 | **アノテーションのみ（破棄しない）** |

#### 確定スキーマ

```json
{
  "ticker": "XYZ",
  "report_source": "アナリストA",
  "claims": [
    {
      "id": 1,
      "claim_type": "competitive_advantage",
      "claim": "ローカルな規模の経済による配送・在庫の効率化",
      "descriptive_label": "配送密度による原価優位",
      "evidence_from_report": "店舗数5,800超、配送センター30拠点（レポートp.8）",
      "supported_by_facts": [3, 4],
      "cagr_connections": [2],
      "rule_evaluation": {
        "applied_rules": ["rule_6", "rule_11"],
        "results": [
          {
            "rule": "rule_6",
            "verdict": "structural",
            "reasoning": "配送密度は競合が容易に再現できない構造的優位"
          },
          {
            "rule": "rule_11",
            "verdict": "pass",
            "reasoning": "フラグメント市場における規模・密度の優位が市場構造と合致"
          }
        ],
        "confidence": 90,
        "confidence_adjustments": [],
        "overall_reasoning": "市場構造との合致が明確。ルール11の典型的な高評価パターン"
      }
    },
    {
      "id": 2,
      "claim_type": "cagr_connection",
      "claim": "店舗密度の拡大 → 配送効率 → マージン改善 → 営業利益CAGR +2pp",
      "descriptive_label": "配送密度→マージン改善経路",
      "source_advantage": 1,
      "rule_evaluation": {
        "applied_rules": ["rule_5", "rule_12"],
        "results": [
          {
            "rule": "rule_5",
            "verdict": "direct",
            "reasoning": "2ステップの因果。配送効率→マージンは10-Kの費用構造から検証可能"
          }
        ],
        "confidence": 80,
        "confidence_adjustments": [],
        "overall_reasoning": "因果メカニズムが直接的で検証可能"
      }
    },
    {
      "id": 3,
      "claim_type": "factual_claim",
      "claim": "店舗数5,829",
      "verification_status": "verified",
      "verification_attempted": [
        "2024年10-K Item 2: 'We operated 5,829 stores as of December 31, 2024'"
      ],
      "what_would_verify": null,
      "confidence_impact": "none",
      "affected_claims": [1]
    },
    {
      "id": 4,
      "claim_type": "factual_claim",
      "claim": "市場シェア25%で業界2位",
      "verification_status": "unverifiable",
      "verification_attempted": [
        "2024年10-K: 市場シェアに関する開示なし",
        "10-K Item 1 Business: 業界内ポジションの定性記述のみ、数値なし"
      ],
      "what_would_verify": "業界団体統計、第三者市場調査レポート（Euromonitor等）",
      "confidence_impact": "moderate",
      "affected_claims": [1]
    }
  ]
}
```

---

### 議論A-4: claim_typeの種別とファクトチェック処理

#### claim_type 3種別

| claim_type | 定義 | 評価に使うルール |
|-----------|------|----------------|
| `competitive_advantage` | 企業が持つ競争優位性の主張 | ルール1,2,3,6,7,8,10,11 + 却下パターンA〜G |
| `cagr_connection` | 優位性がCAGRにどう接続するかの主張 | ルール5,12 |
| `factual_claim` | 数値・事実に関する主張 | ルール9（事実誤認チェック）+ ファクトチェック |

#### ファクトチェック結果の処理

| verification_status | 処理 | confidence への影響 |
|----|----|------|
| `verified` | そのまま通過 | なし |
| `contradicted` | ルール9自動適用。依存する主張の confidence → 10%。**主張自体は削除しない** | critical |
| `unverifiable` | アノテーション付与（検証を試みたソース＋何があれば検証できるか）。依存する主張の confidence を減算（-10〜20%） | moderate |

#### 確立された原則

> **ファクトチェックで検証不可・矛盾が判明しても、主張は破棄しない。**
> KYの判断軸を拡充させることが最優先事項であり、KYの最終判断に届く前に破棄するとフィードバックループが完成しない。
> すべての主張はアノテーション付きでKYに提示する。

---

### 議論B-1: 知識検索ノードの設計

#### 確定事項

| 項目 | 決定 |
|------|------|
| 検索クエリ | 主張テキストを直接使用（LLMクエリ生成は不要） |
| Top-K | ステップ2: 5件（KB1+KB3, 13チャンク中）/ ステップ4: 4件（KB2, 12チャンク中） |
| 常時取得 vs 動的取得 | RAG依存 + 一覧表による取得漏れ緩和 |

#### システムプロンプト確定構成

```
システムプロンプト（常時注入）
├── ゲートキーパー: ルール9, 3（定義＋具体例）          ← 完全版
├── CAGR接続: ルール5(+確度統合補足), 12               ← 完全版
├── 12ルール一覧表（定義のみ、~200トークン）            ← 目次
│   「以下のルールが存在する。詳細はナレッジを参照せよ」
│   ルール1: 能力・仕組み ≠ 結果・実績
│   ルール2: 名詞で表現される属性
│   ルール4: 定量的裏付け
│   ルール6: 構造的 vs 補完的を区別
│   ルール7: 純粋競合への差別化
│   ルール8: 戦略 ≠ 優位性
│   ルール10: ネガティブケース（断念例）
│   ルール11: 業界構造×企業ポジション合致
├── 構造化出力フォーマット指定（JSONスキーマ）
└── 合計: ~1,050トークン
```

#### ナレッジベース確定構成

| KB | 内容 | チャンク数 | 使用ステップ | Top-K |
|----|------|-----------|-------------|-------|
| KB1: ルール集 | ルール1,2,4,6,7,8,10,11（各ルール+具体例+補足） | 8 | ステップ2 | 5 |
| KB2: パターン集 | 却下パターンA〜G + 高評価パターンI〜V | 12 | ステップ4 | 4 |
| KB3: few-shot集 | KY評価付き銘柄例（ORLY, COST, MNST, CHD, LLY） | 5 | ステップ2 | 5 |

#### 設計根拠: なぜRAG依存 + 一覧表か

> 全ルール常時注入（~3,500トークン）は現時点では可能だが、フィードバックループを回すとルールの具体例・補足・few-shotが単調増加する。
> 将来のスケーラビリティを考慮し、RAG依存をベースとする。
> 取得漏れリスクへの緩和策として、12ルールの定義のみ（~200トークン）をシステムプロンプトに目次として配置。
> LLMが全ルールの存在を常に認識するため、RAGで取得されなくてもルール適用の意識が残る。

---

### 議論C-1: ワークフロー分割

#### 結論

**案1: 単一ワークフロー**を採用。

理由:
- Difyでは各LLMノードが独立したAPI呼び出しであり、ステップ2の生成文脈はステップ4に残らない。「自分の生成物に甘い検証」は起きない
- ノード数6（LLM×4 + 知識検索×2）程度であれば、単一ワークフロー内で十分管理できる

---

### 議論C-2: 入力方式

#### 結論

| 入力 | 方式 | 理由 |
|------|------|------|
| アナリストレポート | ファイルアップロード | 銘柄ごとに異なる。量もLLMコンテキストに収まる |
| 10-K / 10-Q | ナレッジベース（KB4、銘柄ごとに作成） | 全文10万トークン超のためファイルアップロードでは処理困難。ステップ1・3で必要箇所をRAG検索 |

---

### 確定ワークフロー

```
入力:
  アナリストレポート → ファイルアップロード
  10-K/10-Q → KB4（銘柄ごとのナレッジベース）

ナレッジベース:
  KB1: ルール集（8チャンク）      — KYの12ルール完全版（定義+具体例+補足）
  KB2: パターン集（12チャンク）    — 却下A〜G + 高評価I〜V
  KB3: few-shot集（5チャンク）     — 銘柄単位のKY評価例
  KB4: 10-K/10-Q（銘柄ごと）      — 法定開示テキスト

ワークフロー（単一、直列10ノード）:

  [アナリストレポート]──┐
                       ↓
  [知識検索: KB4]     → [LLM: ステップ1 主張抽出]
                         入力: レポート + KB4検索結果
                         出力: JSON（3種別のclaims配列）
                           ↓
  [知識検索: KB1+KB3] → [LLM: ステップ2 ルール適用]
                         入力: ステップ1 JSON + KB1/KB3検索結果
                         出力: JSON（rule_evaluation追加）
                           ↓
  [知識検索: KB4]     → [LLM: ステップ3 ファクトチェック]
                         入力: ステップ2 JSON + KB4検索結果
                         出力: JSON（verification_status追加）
                           ↓
  [知識検索: KB2]     → [LLM: ステップ4 検証（JSON）]
                         入力: ステップ3 JSON + KB2検索結果
                         出力: JSON（検証結果追加）
                           ↓
                        [LLM: ステップ5 レポート生成]
                         入力: ステップ4 JSON
                         出力: Markdownレポート（フィードバックテンプレート埋込）
                           ↓
  [知識検索: KB1+KB2] → [LLM: ステップ6 レポート検証]
                         入力: ステップ4 JSON + ステップ5 レポート + KB1/KB2検索結果
                         検証A: JSON-レポート整合（confidence/トーン一致、主張網羅性）
                         検証B: KYのルールとの整合（12ルールに沿った議論か）
                         検証C: 却下/高評価パターンとの整合（表現レベルでのチェック）
                         出力: 検証済み最終レポート or 不整合箇所の指摘付きレポート
                           ↓
                        [最終レポート出力]

システムプロンプト（全LLMノード共通）:
  ├── ゲートキーパー: ルール9, 3（完全版）
  ├── CAGR接続: ルール5(+確度統合補足), 12（完全版）
  ├── 12ルール一覧表（定義のみ、目次として機能）
  └── 構造化出力フォーマット指定（JSONスキーマ）
```

#### ステップ4とステップ6の役割分担

| | ステップ4（JSON検証） | ステップ6（レポート検証） |
|---|---------|---------|
| 検証対象 | JSON（構造化データ） | Markdownレポート（自然言語） |
| 使うKB | KB2（パターン集） | KB1（ルール集）+ KB2（パターン集） |
| 検出できる問題 | ルール適用の漏れ、パターン該当の見落とし | レポート生成時の拡大解釈・トーンの歪み・主張の削ぎ落とし |
| 目的 | 構造化データの論理的整合性 | KYに届くレポートがKYの判断軸に沿った表現になっているか |

> ステップ6は議論7（6.5）で指摘された「推論→出力の断絶」を**レポートレベルで検出する最後の砦**。
> ステップ4がJSONレベルで正しくても、ステップ5でレポートに変換する際に好意的な拡大解釈が入る可能性がある。
> ステップ6はKB1（ルール集）+KB2（パターン集）を参照し、レポートの自然言語表現がKYの投資判断・競争優位性判断と整合しているかを検証する。
