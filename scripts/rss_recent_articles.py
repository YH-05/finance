#!/usr/bin/env python3
"""ç›´è¿‘24æ™‚é–“ã®RSSè¨˜äº‹ã‚’ä¸€è¦§åŒ–ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ."""

from __future__ import annotations

import asyncio
from datetime import datetime, timedelta, timezone
from pathlib import Path

from rss import FeedFetcher, FeedReader


async def main() -> None:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†."""
    data_dir = Path("data/raw/rss")

    print("=" * 80)
    print("RSSè¨˜äº‹å–å¾—é–‹å§‹")
    print("=" * 80)

    # 1. å…¨ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—
    print("\n[1] å…¨ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ä¸­...")
    fetcher = FeedFetcher(data_dir)
    results = await fetcher.fetch_all_async()

    # å–å¾—çµæœã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    success_count = sum(1 for r in results if r.success)
    total_new = sum(r.new_items for r in results if r.success)

    print(f"âœ“ å®Œäº†: {success_count}/{len(results)} ãƒ•ã‚£ãƒ¼ãƒ‰")
    print(f"âœ“ æ–°è¦è¨˜äº‹: {total_new} ä»¶")

    for result in results:
        if result.success:
            print(f"  - {result.feed_id[:8]}: {result.new_items} ä»¶ã®æ–°è¦è¨˜äº‹")
        else:
            print(f"  - {result.feed_id[:8]}: å¤±æ•— ({result.error_message})")

    # 2. ãƒ•ã‚£ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—
    print("\n[2] ãƒ•ã‚£ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—ä¸­...")
    import json

    feeds_file = data_dir / "feeds.json"
    with feeds_file.open("r", encoding="utf-8") as f:
        feeds_data = json.load(f)

    feed_map = {feed["feed_id"]: feed["title"] for feed in feeds_data.get("feeds", [])}

    # 3. å„ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ç›´è¿‘24æ™‚é–“ã®è¨˜äº‹ã‚’å–å¾—
    print("\n[3] ç›´è¿‘24æ™‚é–“ã®è¨˜äº‹ã‚’å–å¾—ä¸­...")
    reader = FeedReader(data_dir)

    # 24æ™‚é–“å‰ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    now = datetime.now(timezone.utc)
    yesterday = now - timedelta(hours=24)

    # å„ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—
    recent_items = []
    for feed_id, feed_title in feed_map.items():
        # å„ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ã‚¢ã‚¤ãƒ†ãƒ ã‚’å–å¾—
        items = reader.get_items(feed_id=feed_id, limit=100)

        for item in items:
            # published ãŒ None ã®å ´åˆã¯ fetched_at ã‚’ä½¿ç”¨
            pub_time_str = item.published or item.fetched_at
            if pub_time_str:
                # ISO 8601 å½¢å¼ã®ãƒ‘ãƒ¼ã‚¹
                try:
                    pub_time = datetime.fromisoformat(
                        pub_time_str.replace("Z", "+00:00")
                    )
                    if pub_time >= yesterday:
                        recent_items.append((pub_time, feed_id, feed_title, item))
                except (ValueError, AttributeError):
                    # ãƒ‘ãƒ¼ã‚¹å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    continue

    # æ–°ã—ã„é †ã«ã‚½ãƒ¼ãƒˆ
    recent_items.sort(key=lambda x: x[0], reverse=True)

    # 4. çµæœã‚’è¡¨ç¤º
    print(f"\nâœ“ ç›´è¿‘24æ™‚é–“ã®è¨˜äº‹: {len(recent_items)} ä»¶")
    print("=" * 80)

    if not recent_items:
        print("\nç›´è¿‘24æ™‚é–“ã®è¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # è¨˜äº‹ã‚’è¡¨ç¤º
    print("\nğŸ“° è¨˜äº‹ä¸€è¦§:\n")
    for idx, (pub_time, feed_id, feed_title, item) in enumerate(recent_items, 1):
        # ãƒ•ã‚£ãƒ¼ãƒ‰åã‚’ä½¿ç”¨
        pass  # feed_title ã¯æ—¢ã«å–å¾—æ¸ˆã¿

        # æ™‚é–“å·®ã‚’è¨ˆç®—
        time_diff = now - pub_time
        hours_ago = int(time_diff.total_seconds() / 3600)

        print(f"{idx}. [{feed_title}]")
        print(f"   {item.title}")
        print(f"   {item.link}")
        print(f"   {hours_ago}æ™‚é–“å‰ ({pub_time.strftime('%Y-%m-%d %H:%M:%S %Z')})")

        if item.summary:
            # ã‚µãƒãƒªãƒ¼ã‚’100æ–‡å­—ã«åˆ¶é™
            summary = (
                item.summary[:100] + "..." if len(item.summary) > 100 else item.summary
            )
            # æ”¹è¡Œã‚’é™¤å»
            summary = summary.replace("\n", " ").replace("\r", " ")
            print(f"   ğŸ“ {summary}")

        print()

    print("=" * 80)
    print(f"åˆè¨ˆ: {len(recent_items)} ä»¶ã®è¨˜äº‹")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
